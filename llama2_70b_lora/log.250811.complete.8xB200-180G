[2025-08-11 23:44:56,319] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-11 23:44:57,162] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
W0811 23:44:57.729000 30422 site-packages/torch/distributed/run.py:766] 
W0811 23:44:57.729000 30422 site-packages/torch/distributed/run.py:766] *****************************************
W0811 23:44:57.729000 30422 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0811 23:44:57.729000 30422 site-packages/torch/distributed/run.py:766] *****************************************
[2025-08-11 23:45:05,102] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-11 23:45:05,145] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-11 23:45:05,169] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-11 23:45:05,176] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-11 23:45:05,195] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-11 23:45:05,205] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-11 23:45:05,206] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-11 23:45:05,213] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-11 23:45:06,059] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-11 23:45:06,068] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-11 23:45:06,086] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-11 23:45:06,094] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-11 23:45:06,153] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-11 23:45:06,162] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-11 23:45:06,162] [INFO] [comm.py:852:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-08-11 23:45:06,206] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-11 23:45:06,209] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-11 23:45:06,209] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-11 23:45:06,217] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-11 23:45:06,219] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-11 23:45:06,219] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-11 23:45:06,272] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-11 23:45:06,283] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-11 23:45:06,326] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-11 23:45:06,337] [INFO] [comm.py:821:init_distributed] cdb=None
libibverbs: Warning: couldn't load driver 'libvmw_pvrdma-rdmav34.so': libvmw_pvrdma-rdmav34.so: cannot open shared object file: No such file or directory
libibverbs: Warning: couldn't load driver 'libvmw_pvrdma-rdmav34.so': libvmw_pvrdma-rdmav34.so: cannot open shared object file: No such file or directory
libibverbs: Warning: couldn't load driver 'libvmw_pvrdma-rdmav34.so': libvmw_pvrdma-rdmav34.so: cannot open shared object file: No such file or directory
libibverbs: Warning: couldn't load driver 'libvmw_pvrdma-rdmav34.so': libvmw_pvrdma-rdmav34.so: cannot open shared object file: No such file or directory
libibverbs: Warning: couldn't load driver 'libvmw_pvrdma-rdmav34.so': libvmw_pvrdma-rdmav34.so: cannot open shared object file: No such file or directory
libibverbs: Warning: couldn't load driver 'libvmw_pvrdma-rdmav34.so': libvmw_pvrdma-rdmav34.so: cannot open shared object file: No such file or directory
libibverbs: Warning: couldn't load driver 'libvmw_pvrdma-rdmav34.so': libvmw_pvrdma-rdmav34.so: cannot open shared object file: No such file or directory
libibverbs: Warning: couldn't load driver 'libvmw_pvrdma-rdmav34.so': libvmw_pvrdma-rdmav34.so: cannot open shared object file: No such file or directory
[2025-08-11 23:46:19,897] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-11 23:46:19,899] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-11 23:46:19,900] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-11 23:46:19,903] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-11 23:46:19,907] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-11 23:46:19,912] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-11 23:46:19,940] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-11 23:46:20,044] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-11 23:46:20,945] [INFO] [partition_parameters.py:366:__exit__] finished initializing model - num_params = 563, num_elems = 68.98B
Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:  21%|██        | 6/29 [00:00<00:02, 10.21it/s]Loading checkpoint shards:  21%|██        | 6/29 [00:00<00:02, 10.26it/s]Loading checkpoint shards:  21%|██        | 6/29 [00:00<00:02, 10.23it/s]Loading checkpoint shards:  21%|██        | 6/29 [00:00<00:02, 10.21it/s]Loading checkpoint shards:  21%|██        | 6/29 [00:00<00:02, 10.23it/s]Loading checkpoint shards:  21%|██        | 6/29 [00:00<00:02, 10.24it/s]Loading checkpoint shards:  21%|██        | 6/29 [00:00<00:02, 10.28it/s]Loading checkpoint shards:   3%|▎         | 1/29 [00:00<00:22,  1.27it/s]Loading checkpoint shards:   7%|▋         | 2/29 [00:01<00:20,  1.32it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:06,  3.26it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:06,  3.26it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:06,  3.26it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:06,  3.27it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:06,  3.26it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:06,  3.26it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:06,  3.26it/s]Loading checkpoint shards:  10%|█         | 3/29 [00:02<00:20,  1.30it/s]Loading checkpoint shards:  31%|███       | 9/29 [00:02<00:07,  2.57it/s]Loading checkpoint shards:  31%|███       | 9/29 [00:02<00:07,  2.57it/s]Loading checkpoint shards:  31%|███       | 9/29 [00:02<00:07,  2.57it/s]Loading checkpoint shards:  31%|███       | 9/29 [00:02<00:07,  2.57it/s]Loading checkpoint shards:  31%|███       | 9/29 [00:02<00:07,  2.57it/s]Loading checkpoint shards:  31%|███       | 9/29 [00:02<00:07,  2.57it/s]Loading checkpoint shards:  31%|███       | 9/29 [00:02<00:07,  2.57it/s]Loading checkpoint shards:  14%|█▍        | 4/29 [00:03<00:19,  1.29it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:03<00:08,  2.15it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:03<00:08,  2.15it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:03<00:08,  2.15it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:03<00:08,  2.15it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:03<00:08,  2.15it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:03<00:08,  2.15it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:03<00:08,  2.15it/s]Loading checkpoint shards:  17%|█▋        | 5/29 [00:03<00:18,  1.32it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:04<00:09,  1.84it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:04<00:09,  1.84it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:04<00:09,  1.84it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:04<00:09,  1.84it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:04<00:09,  1.84it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:04<00:09,  1.84it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:04<00:09,  1.84it/s]Loading checkpoint shards:  21%|██        | 6/29 [00:04<00:17,  1.34it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:05<00:10,  1.70it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:05<00:10,  1.70it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:05<00:10,  1.70it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:05<00:10,  1.70it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:05<00:10,  1.70it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:05<00:10,  1.70it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:05<00:10,  1.70it/s]Loading checkpoint shards:  24%|██▍       | 7/29 [00:05<00:16,  1.34it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:05<00:10,  1.60it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:05<00:10,  1.60it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:05<00:10,  1.60it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:05<00:10,  1.60it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:05<00:10,  1.60it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:05<00:10,  1.60it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:05<00:10,  1.60it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:06<00:15,  1.32it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:06<00:09,  1.52it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:06<00:09,  1.52it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:06<00:09,  1.52it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:06<00:09,  1.52it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:06<00:09,  1.52it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:06<00:09,  1.52it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:06<00:09,  1.52it/s]Loading checkpoint shards:  31%|███       | 9/29 [00:06<00:15,  1.31it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:07<00:09,  1.45it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:07<00:09,  1.45it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:07<00:09,  1.45it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:07<00:09,  1.45it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:07<00:09,  1.45it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:07<00:09,  1.45it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:07<00:09,  1.45it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:07<00:14,  1.33it/s]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:08<00:09,  1.39it/s]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:08<00:09,  1.39it/s]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:08<00:09,  1.39it/s]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:08<00:09,  1.39it/s]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:08<00:09,  1.39it/s]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:08<00:09,  1.39it/s]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:08<00:09,  1.39it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:08<00:13,  1.34it/s]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:08<00:08,  1.39it/s]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:08<00:08,  1.39it/s]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:08<00:08,  1.39it/s]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:08<00:08,  1.39it/s]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:08<00:08,  1.39it/s]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:08<00:08,  1.39it/s]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:08<00:08,  1.39it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:09<00:12,  1.35it/s]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:09<00:07,  1.38it/s]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:09<00:07,  1.38it/s]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:09<00:07,  1.38it/s]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:09<00:07,  1.38it/s]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:09<00:07,  1.38it/s]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:09<00:07,  1.38it/s]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:09<00:07,  1.38it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:09<00:12,  1.33it/s]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:10<00:07,  1.38it/s]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:10<00:07,  1.38it/s]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:10<00:07,  1.38it/s]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:10<00:07,  1.38it/s]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:10<00:07,  1.38it/s]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:10<00:07,  1.38it/s]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:10<00:07,  1.38it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:10<00:11,  1.32it/s]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:11<00:06,  1.36it/s]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:11<00:06,  1.36it/s]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:11<00:06,  1.36it/s]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:11<00:06,  1.36it/s]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:11<00:06,  1.36it/s]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:11<00:06,  1.36it/s]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:11<00:06,  1.36it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:11<00:10,  1.33it/s]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:11<00:06,  1.33it/s]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:11<00:06,  1.33it/s]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:11<00:06,  1.33it/s]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:11<00:06,  1.33it/s]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:11<00:06,  1.33it/s]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:11<00:06,  1.33it/s]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:11<00:06,  1.33it/s]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:12<00:09,  1.34it/s]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:12<00:05,  1.34it/s]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:12<00:05,  1.34it/s]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:12<00:05,  1.34it/s]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:12<00:05,  1.34it/s]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:12<00:05,  1.34it/s]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:12<00:05,  1.34it/s]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:12<00:05,  1.34it/s]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:12<00:08,  1.35it/s]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:13<00:04,  1.35it/s]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:13<00:04,  1.35it/s]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:13<00:04,  1.35it/s]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:13<00:04,  1.35it/s]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:13<00:04,  1.35it/s]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:13<00:04,  1.35it/s]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:13<00:04,  1.35it/s]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:13<00:08,  1.33it/s]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:14<00:03,  1.35it/s]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:14<00:03,  1.35it/s]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:14<00:03,  1.35it/s]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:14<00:03,  1.35it/s]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:14<00:03,  1.35it/s]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:14<00:03,  1.35it/s]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:14<00:03,  1.35it/s]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:14<00:07,  1.31it/s]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:14<00:02,  1.34it/s]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:14<00:02,  1.34it/s]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:14<00:02,  1.34it/s]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:14<00:02,  1.34it/s]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:14<00:02,  1.34it/s]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:14<00:02,  1.34it/s]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:14<00:02,  1.34it/s]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:15<00:06,  1.33it/s]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:15<00:02,  1.31it/s]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:15<00:02,  1.31it/s]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:15<00:02,  1.31it/s]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:15<00:02,  1.31it/s]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:15<00:02,  1.31it/s]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:15<00:02,  1.31it/s]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:15<00:02,  1.31it/s]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:15<00:05,  1.34it/s]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:16<00:01,  1.32it/s]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:16<00:01,  1.32it/s]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:16<00:01,  1.32it/s]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:16<00:01,  1.32it/s]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:16<00:01,  1.32it/s]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:16<00:01,  1.32it/s]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:16<00:01,  1.32it/s]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:16<00:05,  1.34it/s]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:17<00:00,  1.33it/s]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:17<00:00,  1.33it/s]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:17<00:00,  1.33it/s]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:17<00:00,  1.33it/s]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:17<00:00,  1.33it/s]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:17<00:00,  1.33it/s]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:17<00:00,  1.33it/s]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:17<00:04,  1.31it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.39it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.39it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.39it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.39it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.39it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.39it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.63it/s]
Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.63it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.39it/s]
Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.63it/s]
Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.63it/s]
Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.63it/s]
Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.63it/s]
Loading checkpoint shards: 100%|██████████| 29/29 [00:17<00:00,  1.63it/s]
Loading checkpoint shards:  83%|████████▎ | 24/29 [00:18<00:03,  1.29it/s]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:18<00:03,  1.31it/s]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:19<00:02,  1.33it/s]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:20<00:01,  1.33it/s]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:21<00:00,  1.31it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:21<00:00,  1.41it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:21<00:00,  1.33it/s]
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): CustomLlamaForCausalLM(
      (model): LlamaModel(
        (embed_tokens): Embedding(32000, 8192)
        (layers): ModuleList(
          (0-79): 80 x LlamaDecoderLayer(
            (self_attn): LlamaFlashAttention2(
              (qkv_proj): lora.Linear(
                (base_layer): Linear(in_features=8192, out_features=10240, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=8192, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=10240, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (o_proj): lora.Linear(
                (base_layer): Linear(in_features=8192, out_features=8192, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=8192, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=8192, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(in_features=8192, out_features=28672, bias=False)
              (up_proj): Linear(in_features=8192, out_features=28672, bias=False)
              (down_proj): Linear(in_features=28672, out_features=8192, bias=False)
              (act_fn): SiLU()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
      )
      (lm_head): Linear(in_features=8192, out_features=32000, bias=False)
    )
  )
)
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
Parameter Offload - Persistent parameters statistics: param_count = 161, numel = 1318912
wandb: Currently logged in as: vchua to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/shadeform/work/dev/sf-250811-b200-mlperf/mlperf-training/llama2_70b_lora/wandb/run-20250811_234648-2025-08-11_23-45-04---llama2-70b-fused-qkv-mlperf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 2025-08-11_23-45-04---llama2-70b-fused-qkv-mlperf
wandb: ⭐️ View project at https://wandb.ai/vchua/mlperf-lora
wandb: 🚀 View run at https://wandb.ai/vchua/mlperf-lora/runs/2025-08-11_23-45-04---llama2-70b-fused-qkv-mlperf
:::MLLOG {"namespace": "", "time_ms": 1754981209274, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": "True", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1754981209275, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "llama2_70b_lora", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 97}}
:::MLLOG {"namespace": "", "time_ms": 1754981209275, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 101}}
:::MLLOG {"namespace": "", "time_ms": 1754981209275, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 105}}
:::MLLOG {"namespace": "", "time_ms": 1754981209275, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108}}
:::MLLOG {"namespace": "", "time_ms": 1754981209275, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 112}}
:::MLLOG {"namespace": "", "time_ms": 1754981209275, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1754981209275, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1754981209276, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 8, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1754981209276, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3901, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1754981209276, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 173, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 132}}
:::MLLOG {"namespace": "", "time_ms": 1754981209276, "event_type": "POINT_IN_TIME", "key": "seed", "value": 101, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1754981209276, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.0, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1754981209276, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 1024, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 138}}
:::MLLOG {"namespace": "", "time_ms": 1754981209276, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.0001, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 139}}
:::MLLOG {"namespace": "", "time_ms": 1754981209276, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 0.3, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 140}}
:::MLLOG {"namespace": "", "time_ms": 1754981209276, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0004, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 141}}
:::MLLOG {"namespace": "", "time_ms": 1754981209277, "event_type": "POINT_IN_TIME", "key": "lora_alpha", "value": 32, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142}}
:::MLLOG {"namespace": "", "time_ms": 1754981209277, "event_type": "POINT_IN_TIME", "key": "lora_rank", "value": 16, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1754981209277, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 144}}
:::MLLOG {"namespace": "", "time_ms": 1754981209277, "event_type": "INTERVAL_START", "key": "init_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 145}}
:::MLLOG {"namespace": "", "time_ms": 1754981209277, "event_type": "INTERVAL_END", "key": "init_stop", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147}}
:::MLLOG {"namespace": "", "time_ms": 1754981209277, "event_type": "INTERVAL_START", "key": "run_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 148}}
  0%|          | 0/1024 [00:00<?, ?it/s]  0%|          | 1/1024 [00:06<1:46:28,  6.25s/it]  0%|          | 2/1024 [00:11<1:33:41,  5.50s/it]  0%|          | 3/1024 [00:16<1:29:15,  5.24s/it]  0%|          | 4/1024 [00:21<1:27:15,  5.13s/it]  0%|          | 5/1024 [00:26<1:26:07,  5.07s/it]  1%|          | 6/1024 [00:31<1:25:26,  5.04s/it]  1%|          | 7/1024 [00:36<1:25:00,  5.02s/it]  1%|          | 8/1024 [00:41<1:24:50,  5.01s/it]  1%|          | 9/1024 [00:46<1:24:42,  5.01s/it]  1%|          | 10/1024 [00:51<1:24:38,  5.01s/it]  1%|          | 11/1024 [00:56<1:24:40,  5.01s/it]  1%|          | 12/1024 [01:01<1:24:36,  5.02s/it]  1%|▏         | 13/1024 [01:06<1:24:46,  5.03s/it]  1%|▏         | 14/1024 [01:11<1:24:44,  5.03s/it]  1%|▏         | 15/1024 [01:16<1:24:52,  5.05s/it]  2%|▏         | 16/1024 [01:21<1:25:01,  5.06s/it]  2%|▏         | 17/1024 [01:26<1:24:47,  5.05s/it]  2%|▏         | 18/1024 [01:31<1:24:39,  5.05s/it]  2%|▏         | 19/1024 [01:36<1:24:34,  5.05s/it]  2%|▏         | 20/1024 [01:41<1:24:33,  5.05s/it]  2%|▏         | 21/1024 [01:46<1:24:36,  5.06s/it]  2%|▏         | 22/1024 [01:51<1:24:26,  5.06s/it]  2%|▏         | 23/1024 [01:56<1:24:15,  5.05s/it]  2%|▏         | 24/1024 [02:01<1:24:09,  5.05s/it]                                                   {'loss': 2.2057, 'grad_norm': 0.18197944499533544, 'learning_rate': 0.00039950229122806075, 'epoch': 0.05}
  2%|▏         | 24/1024 [02:01<1:24:09,  5.05s/it]:::MLLOG {"namespace": "", "time_ms": 1754981331044, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 2.2057, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 192}}
  2%|▏         | 25/1024 [02:06<1:24:00,  5.05s/it]                                                   {'loss': 1.4556, 'grad_norm': 0.2546346614206966, 'learning_rate': 0.00039945809133573807, 'epoch': 0.05}
  2%|▏         | 25/1024 [02:06<1:24:00,  5.05s/it]  3%|▎         | 26/1024 [02:11<1:24:02,  5.05s/it]  3%|▎         | 27/1024 [02:16<1:24:00,  5.06s/it]  3%|▎         | 28/1024 [02:21<1:23:56,  5.06s/it]  3%|▎         | 29/1024 [02:27<1:23:48,  5.05s/it]  3%|▎         | 30/1024 [02:32<1:23:44,  5.06s/it]  3%|▎         | 31/1024 [02:37<1:23:39,  5.05s/it]  3%|▎         | 32/1024 [02:42<1:23:29,  5.05s/it]  3%|▎         | 33/1024 [02:47<1:23:34,  5.06s/it]  3%|▎         | 34/1024 [02:52<1:23:28,  5.06s/it]  3%|▎         | 35/1024 [02:57<1:23:26,  5.06s/it]  4%|▎         | 36/1024 [03:02<1:23:28,  5.07s/it]  4%|▎         | 37/1024 [03:07<1:23:22,  5.07s/it]  4%|▎         | 38/1024 [03:12<1:23:15,  5.07s/it]  4%|▍         | 39/1024 [03:17<1:23:13,  5.07s/it]  4%|▍         | 40/1024 [03:22<1:23:35,  5.10s/it]  4%|▍         | 41/1024 [03:27<1:23:19,  5.09s/it]  4%|▍         | 42/1024 [03:33<1:23:44,  5.12s/it]  4%|▍         | 43/1024 [03:38<1:23:24,  5.10s/it]  4%|▍         | 44/1024 [03:43<1:22:57,  5.08s/it]  4%|▍         | 45/1024 [03:48<1:22:55,  5.08s/it]  4%|▍         | 46/1024 [03:53<1:22:41,  5.07s/it]  5%|▍         | 47/1024 [03:58<1:23:11,  5.11s/it]  5%|▍         | 48/1024 [04:03<1:22:57,  5.10s/it]                                                   {'loss': 1.3804, 'grad_norm': 0.1236580087743346, 'learning_rate': 0.0003979244034926402, 'epoch': 0.1}
  5%|▍         | 48/1024 [04:03<1:22:57,  5.10s/it]  5%|▍         | 49/1024 [04:08<1:22:49,  5.10s/it]  5%|▍         | 50/1024 [04:13<1:22:44,  5.10s/it]  5%|▍         | 51/1024 [04:18<1:22:28,  5.09s/it]  5%|▌         | 52/1024 [04:23<1:22:22,  5.08s/it]  5%|▌         | 53/1024 [04:29<1:22:28,  5.10s/it]  5%|▌         | 54/1024 [04:34<1:22:35,  5.11s/it]  5%|▌         | 55/1024 [04:39<1:22:20,  5.10s/it]  5%|▌         | 56/1024 [04:44<1:22:40,  5.12s/it]  6%|▌         | 57/1024 [04:49<1:22:14,  5.10s/it]  6%|▌         | 58/1024 [04:54<1:21:55,  5.09s/it]  6%|▌         | 59/1024 [04:59<1:22:16,  5.12s/it]  6%|▌         | 60/1024 [05:04<1:21:52,  5.10s/it]  6%|▌         | 61/1024 [05:09<1:21:37,  5.09s/it]  6%|▌         | 62/1024 [05:14<1:21:33,  5.09s/it]  6%|▌         | 63/1024 [05:19<1:21:19,  5.08s/it]  6%|▋         | 64/1024 [05:25<1:21:08,  5.07s/it]  6%|▋         | 65/1024 [05:30<1:21:05,  5.07s/it]  6%|▋         | 66/1024 [05:35<1:20:51,  5.06s/it]  7%|▋         | 67/1024 [05:40<1:20:42,  5.06s/it]  7%|▋         | 68/1024 [05:45<1:20:40,  5.06s/it]  7%|▋         | 69/1024 [05:50<1:20:39,  5.07s/it]  7%|▋         | 70/1024 [05:55<1:20:41,  5.08s/it]  7%|▋         | 71/1024 [06:00<1:20:41,  5.08s/it]  7%|▋         | 72/1024 [06:05<1:21:02,  5.11s/it]                                                   {'loss': 1.3257, 'grad_norm': 0.1299464058273516, 'learning_rate': 0.0003952739462660042, 'epoch': 0.15}
  7%|▋         | 72/1024 [06:05<1:21:02,  5.11s/it]:::MLLOG {"namespace": "", "time_ms": 1754981575012, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3257, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 576}}
  7%|▋         | 73/1024 [06:10<1:21:04,  5.11s/it]                                                   {'loss': 1.3154, 'grad_norm': 0.12929765571764593, 'learning_rate': 0.0003951404260077057, 'epoch': 0.15}
  7%|▋         | 73/1024 [06:10<1:21:04,  5.11s/it]  7%|▋         | 74/1024 [06:16<1:21:21,  5.14s/it]  7%|▋         | 75/1024 [06:21<1:20:59,  5.12s/it]  7%|▋         | 76/1024 [06:26<1:20:37,  5.10s/it]  8%|▊         | 77/1024 [06:31<1:20:32,  5.10s/it]  8%|▊         | 78/1024 [06:36<1:20:19,  5.09s/it]  8%|▊         | 79/1024 [06:41<1:19:59,  5.08s/it]  8%|▊         | 80/1024 [06:46<1:19:54,  5.08s/it]  8%|▊         | 81/1024 [06:51<1:19:43,  5.07s/it]  8%|▊         | 82/1024 [06:56<1:20:04,  5.10s/it]  8%|▊         | 83/1024 [07:01<1:19:45,  5.09s/it]  8%|▊         | 84/1024 [07:06<1:19:31,  5.08s/it]  8%|▊         | 85/1024 [07:11<1:19:25,  5.07s/it]  8%|▊         | 86/1024 [07:16<1:19:27,  5.08s/it]  8%|▊         | 87/1024 [07:22<1:19:21,  5.08s/it]  9%|▊         | 88/1024 [07:27<1:19:45,  5.11s/it]  9%|▊         | 89/1024 [07:32<1:19:25,  5.10s/it]  9%|▉         | 90/1024 [07:37<1:19:18,  5.09s/it]  9%|▉         | 91/1024 [07:42<1:19:22,  5.10s/it]  9%|▉         | 92/1024 [07:47<1:19:06,  5.09s/it]  9%|▉         | 93/1024 [07:52<1:18:51,  5.08s/it]  9%|▉         | 94/1024 [07:57<1:18:36,  5.07s/it]  9%|▉         | 95/1024 [08:02<1:18:32,  5.07s/it]  9%|▉         | 96/1024 [08:07<1:18:29,  5.07s/it]                                                   {'loss': 1.316, 'grad_norm': 0.26829256317099454, 'learning_rate': 0.0003915652826055066, 'epoch': 0.2}
  9%|▉         | 96/1024 [08:07<1:18:29,  5.07s/it]  9%|▉         | 97/1024 [08:12<1:18:16,  5.07s/it] 10%|▉         | 98/1024 [08:17<1:18:10,  5.06s/it] 10%|▉         | 99/1024 [08:23<1:18:35,  5.10s/it] 10%|▉         | 100/1024 [08:28<1:18:28,  5.10s/it] 10%|▉         | 101/1024 [08:33<1:18:13,  5.08s/it] 10%|▉         | 102/1024 [08:38<1:18:12,  5.09s/it] 10%|█         | 103/1024 [08:43<1:18:26,  5.11s/it] 10%|█         | 104/1024 [08:48<1:18:07,  5.09s/it] 10%|█         | 105/1024 [08:53<1:17:59,  5.09s/it] 10%|█         | 106/1024 [08:58<1:18:00,  5.10s/it] 10%|█         | 107/1024 [09:03<1:17:40,  5.08s/it] 11%|█         | 108/1024 [09:08<1:17:29,  5.08s/it] 11%|█         | 109/1024 [09:13<1:17:20,  5.07s/it] 11%|█         | 110/1024 [09:19<1:17:06,  5.06s/it] 11%|█         | 111/1024 [09:24<1:17:05,  5.07s/it] 11%|█         | 112/1024 [09:29<1:17:02,  5.07s/it] 11%|█         | 113/1024 [09:34<1:17:03,  5.07s/it] 11%|█         | 114/1024 [09:39<1:17:18,  5.10s/it] 11%|█         | 115/1024 [09:44<1:17:25,  5.11s/it] 11%|█▏        | 116/1024 [09:49<1:17:02,  5.09s/it] 11%|█▏        | 117/1024 [09:54<1:16:51,  5.08s/it] 12%|█▏        | 118/1024 [09:59<1:17:07,  5.11s/it] 12%|█▏        | 119/1024 [10:04<1:16:56,  5.10s/it] 12%|█▏        | 120/1024 [10:10<1:16:52,  5.10s/it]                                                    {'loss': 1.319, 'grad_norm': 0.14767041025227146, 'learning_rate': 0.00038681851008085183, 'epoch': 0.25}
 12%|█▏        | 120/1024 [10:10<1:16:52,  5.10s/it]:::MLLOG {"namespace": "", "time_ms": 1754981819297, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.319, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 960}}
 12%|█▏        | 121/1024 [10:15<1:16:32,  5.09s/it]                                                    {'loss': 1.3292, 'grad_norm': 0.1267975732209937, 'learning_rate': 0.0003865985597669478, 'epoch': 0.25}
 12%|█▏        | 121/1024 [10:15<1:16:32,  5.09s/it] 12%|█▏        | 122/1024 [10:20<1:16:23,  5.08s/it] 12%|█▏        | 123/1024 [10:25<1:16:17,  5.08s/it] 12%|█▏        | 124/1024 [10:30<1:16:14,  5.08s/it] 12%|█▏        | 125/1024 [10:35<1:16:29,  5.11s/it] 12%|█▏        | 126/1024 [10:40<1:16:12,  5.09s/it] 12%|█▏        | 127/1024 [10:45<1:15:59,  5.08s/it] 12%|█▎        | 128/1024 [10:50<1:15:42,  5.07s/it] 13%|█▎        | 129/1024 [10:55<1:15:58,  5.09s/it] 13%|█▎        | 130/1024 [11:00<1:15:39,  5.08s/it] 13%|█▎        | 131/1024 [11:05<1:15:34,  5.08s/it] 13%|█▎        | 132/1024 [11:11<1:15:43,  5.09s/it] 13%|█▎        | 133/1024 [11:16<1:15:30,  5.08s/it] 13%|█▎        | 134/1024 [11:21<1:15:17,  5.08s/it] 13%|█▎        | 135/1024 [11:26<1:15:46,  5.11s/it] 13%|█▎        | 136/1024 [11:31<1:15:51,  5.13s/it] 13%|█▎        | 137/1024 [11:36<1:15:28,  5.10s/it] 13%|█▎        | 138/1024 [11:41<1:15:11,  5.09s/it] 14%|█▎        | 139/1024 [11:46<1:15:04,  5.09s/it] 14%|█▎        | 140/1024 [11:51<1:14:53,  5.08s/it] 14%|█▍        | 141/1024 [11:56<1:14:49,  5.08s/it] 14%|█▍        | 142/1024 [12:01<1:14:36,  5.08s/it] 14%|█▍        | 143/1024 [12:06<1:14:30,  5.07s/it] 14%|█▍        | 144/1024 [12:12<1:14:32,  5.08s/it]                                                    {'loss': 1.3008, 'grad_norm': 0.3048108365007133, 'learning_rate': 0.0003810593518636238, 'epoch': 0.3}
 14%|█▍        | 144/1024 [12:12<1:14:32,  5.08s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:01<00:15,  1.32it/s][A
 14%|█▎        | 3/22 [00:03<00:20,  1.07s/it][A
 18%|█▊        | 4/22 [00:04<00:22,  1.23s/it][A
 23%|██▎       | 5/22 [00:06<00:22,  1.33s/it][A
 27%|██▋       | 6/22 [00:07<00:22,  1.39s/it][A
 32%|███▏      | 7/22 [00:09<00:21,  1.42s/it][A
 36%|███▋      | 8/22 [00:10<00:20,  1.45s/it][A
 41%|████      | 9/22 [00:12<00:19,  1.46s/it][A
 45%|████▌     | 10/22 [00:13<00:17,  1.47s/it][A
 50%|█████     | 11/22 [00:15<00:16,  1.48s/it][A
 55%|█████▍    | 12/22 [00:16<00:14,  1.49s/it][A
 59%|█████▉    | 13/22 [00:18<00:13,  1.50s/it][A
 64%|██████▎   | 14/22 [00:19<00:11,  1.50s/it][A
 68%|██████▊   | 15/22 [00:21<00:10,  1.50s/it][A
 73%|███████▎  | 16/22 [00:22<00:09,  1.51s/it][A
 77%|███████▋  | 17/22 [00:24<00:07,  1.51s/it][A
 82%|████████▏ | 18/22 [00:25<00:06,  1.51s/it][A
 86%|████████▋ | 19/22 [00:27<00:04,  1.52s/it][A
 91%|█████████ | 20/22 [00:28<00:03,  1.51s/it][A
 95%|█████████▌| 21/22 [00:30<00:01,  1.51s/it][A
100%|██████████| 22/22 [00:31<00:00,  1.51s/it][A                                                    
                                               [A{'eval_loss': 0.9473972916603088, 'eval_runtime': 33.1775, 'eval_samples_per_second': 5.214, 'eval_steps_per_second': 0.663, 'epoch': 0.3}
 14%|█▍        | 144/1024 [12:45<1:14:32,  5.08s/it]
100%|██████████| 22/22 [00:31<00:00,  1.51s/it][A
                                               [A 14%|█▍        | 145/1024 [12:50<3:40:32, 15.05s/it] 14%|█▍        | 146/1024 [12:55<2:56:19, 12.05s/it] 14%|█▍        | 147/1024 [13:00<2:25:28,  9.95s/it] 14%|█▍        | 148/1024 [13:05<2:04:07,  8.50s/it] 15%|█▍        | 149/1024 [13:10<1:49:01,  7.48s/it] 15%|█▍        | 150/1024 [13:15<1:38:26,  6.76s/it] 15%|█▍        | 151/1024 [13:20<1:30:56,  6.25s/it] 15%|█▍        | 152/1024 [13:25<1:25:48,  5.90s/it] 15%|█▍        | 153/1024 [13:31<1:22:06,  5.66s/it] 15%|█▌        | 154/1024 [13:36<1:19:51,  5.51s/it] 15%|█▌        | 155/1024 [13:41<1:17:48,  5.37s/it] 15%|█▌        | 156/1024 [13:46<1:16:59,  5.32s/it] 15%|█▌        | 157/1024 [13:51<1:15:41,  5.24s/it] 15%|█▌        | 158/1024 [13:56<1:14:48,  5.18s/it] 16%|█▌        | 159/1024 [14:01<1:14:06,  5.14s/it] 16%|█▌        | 160/1024 [14:06<1:13:56,  5.13s/it] 16%|█▌        | 161/1024 [14:11<1:13:32,  5.11s/it] 16%|█▌        | 162/1024 [14:16<1:13:43,  5.13s/it] 16%|█▌        | 163/1024 [14:22<1:13:25,  5.12s/it] 16%|█▌        | 164/1024 [14:27<1:13:08,  5.10s/it] 16%|█▌        | 165/1024 [14:32<1:12:55,  5.09s/it] 16%|█▌        | 166/1024 [14:37<1:12:40,  5.08s/it] 16%|█▋        | 167/1024 [14:42<1:12:23,  5.07s/it] 16%|█▋        | 168/1024 [14:47<1:12:17,  5.07s/it]                                                    {'loss': 1.3067, 'grad_norm': 0.15656417013172982, 'learning_rate': 0.0003743190173311902, 'epoch': 0.34}
 16%|█▋        | 168/1024 [14:47<1:12:17,  5.07s/it]:::MLLOG {"namespace": "", "time_ms": 1754982096598, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3067, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 1344}}
 17%|█▋        | 169/1024 [14:52<1:12:19,  5.07s/it]                                                    {'loss': 1.3174, 'grad_norm': 0.16776697022819945, 'learning_rate': 0.0003740173982217423, 'epoch': 0.35}
 17%|█▋        | 169/1024 [14:52<1:12:19,  5.07s/it] 17%|█▋        | 170/1024 [14:57<1:12:08,  5.07s/it] 17%|█▋        | 171/1024 [15:02<1:12:33,  5.10s/it] 17%|█▋        | 172/1024 [15:07<1:12:15,  5.09s/it] 17%|█▋        | 173/1024 [15:12<1:12:00,  5.08s/it] 17%|█▋        | 174/1024 [15:17<1:11:44,  5.06s/it] 17%|█▋        | 175/1024 [15:22<1:12:13,  5.10s/it] 17%|█▋        | 176/1024 [15:28<1:11:56,  5.09s/it] 17%|█▋        | 177/1024 [15:33<1:11:43,  5.08s/it] 17%|█▋        | 178/1024 [15:38<1:11:26,  5.07s/it] 17%|█▋        | 179/1024 [15:43<1:11:20,  5.07s/it] 18%|█▊        | 180/1024 [15:48<1:11:13,  5.06s/it] 18%|█▊        | 181/1024 [15:53<1:11:11,  5.07s/it] 18%|█▊        | 182/1024 [15:58<1:11:03,  5.06s/it] 18%|█▊        | 183/1024 [16:03<1:11:04,  5.07s/it] 18%|█▊        | 184/1024 [16:08<1:10:59,  5.07s/it] 18%|█▊        | 185/1024 [16:13<1:10:52,  5.07s/it] 18%|█▊        | 186/1024 [16:18<1:10:52,  5.07s/it] 18%|█▊        | 187/1024 [16:23<1:10:42,  5.07s/it] 18%|█▊        | 188/1024 [16:28<1:10:45,  5.08s/it] 18%|█▊        | 189/1024 [16:33<1:10:36,  5.07s/it] 19%|█▊        | 190/1024 [16:39<1:10:58,  5.11s/it] 19%|█▊        | 191/1024 [16:44<1:10:44,  5.10s/it] 19%|█▉        | 192/1024 [16:49<1:10:31,  5.09s/it]                                                    {'loss': 1.3163, 'grad_norm': 0.15497391840267155, 'learning_rate': 0.00036663403294038264, 'epoch': 0.39}
 19%|█▉        | 192/1024 [16:49<1:10:31,  5.09s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:01<00:15,  1.33it/s][A
 14%|█▎        | 3/22 [00:02<00:20,  1.06s/it][A
 18%|█▊        | 4/22 [00:04<00:22,  1.23s/it][A
 23%|██▎       | 5/22 [00:06<00:22,  1.33s/it][A
 27%|██▋       | 6/22 [00:07<00:22,  1.38s/it][A
 32%|███▏      | 7/22 [00:09<00:21,  1.42s/it][A
 36%|███▋      | 8/22 [00:10<00:20,  1.44s/it][A
 41%|████      | 9/22 [00:12<00:19,  1.47s/it][A
 45%|████▌     | 10/22 [00:13<00:17,  1.47s/it][A
 50%|█████     | 11/22 [00:15<00:16,  1.49s/it][A
 55%|█████▍    | 12/22 [00:16<00:14,  1.49s/it][A
 59%|█████▉    | 13/22 [00:18<00:13,  1.49s/it][A
 64%|██████▎   | 14/22 [00:19<00:11,  1.49s/it][A
 68%|██████▊   | 15/22 [00:21<00:10,  1.50s/it][A
 73%|███████▎  | 16/22 [00:22<00:08,  1.50s/it][A
 77%|███████▋  | 17/22 [00:24<00:07,  1.50s/it][A
 82%|████████▏ | 18/22 [00:25<00:05,  1.50s/it][A
 86%|████████▋ | 19/22 [00:27<00:04,  1.50s/it][A
 91%|█████████ | 20/22 [00:28<00:03,  1.50s/it][A
 95%|█████████▌| 21/22 [00:30<00:01,  1.52s/it][A
100%|██████████| 22/22 [00:31<00:00,  1.52s/it][A                                                    
                                               [A{'eval_loss': 0.9374502301216125, 'eval_runtime': 33.119, 'eval_samples_per_second': 5.224, 'eval_steps_per_second': 0.664, 'epoch': 0.39}
 19%|█▉        | 192/1024 [17:22<1:10:31,  5.09s/it]
100%|██████████| 22/22 [00:31<00:00,  1.52s/it][A
                                               [A:::MLLOG {"namespace": "", "time_ms": 1754982251640, "event_type": "INTERVAL_END", "key": "block_stop", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 174, "samples_count": 1536}}
:::MLLOG {"namespace": "", "time_ms": 1754982251640, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9374502301216125, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 179, "samples_count": 1536}}
:::MLLOG {"namespace": "", "time_ms": 1754982251641, "event_type": "INTERVAL_START", "key": "block_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 184, "samples_count": 192}}
 19%|█▉        | 193/1024 [17:27<3:28:33, 15.06s/it]                                                    {'loss': 1.2539, 'grad_norm': 0.1489426058234542, 'learning_rate': 0.0003662939224605091, 'epoch': 0.4}
 19%|█▉        | 193/1024 [17:27<3:28:33, 15.06s/it] 19%|█▉        | 194/1024 [17:32<2:46:57, 12.07s/it] 19%|█▉        | 195/1024 [17:37<2:17:41,  9.97s/it] 19%|█▉        | 196/1024 [17:42<1:57:12,  8.49s/it] 19%|█▉        | 197/1024 [17:47<1:43:22,  7.50s/it] 19%|█▉        | 198/1024 [17:53<1:33:16,  6.78s/it] 19%|█▉        | 199/1024 [17:58<1:26:12,  6.27s/it] 20%|█▉        | 200/1024 [18:03<1:21:28,  5.93s/it] 20%|█▉        | 201/1024 [18:08<1:17:47,  5.67s/it] 20%|█▉        | 202/1024 [18:13<1:15:19,  5.50s/it] 20%|█▉        | 203/1024 [18:18<1:13:29,  5.37s/it] 20%|█▉        | 204/1024 [18:23<1:12:07,  5.28s/it] 20%|██        | 205/1024 [18:28<1:11:08,  5.21s/it] 20%|██        | 206/1024 [18:33<1:10:53,  5.20s/it] 20%|██        | 207/1024 [18:38<1:10:29,  5.18s/it] 20%|██        | 208/1024 [18:44<1:10:19,  5.17s/it] 20%|██        | 209/1024 [18:49<1:10:16,  5.17s/it] 21%|██        | 210/1024 [18:54<1:10:20,  5.19s/it] 21%|██        | 211/1024 [18:59<1:09:45,  5.15s/it] 21%|██        | 212/1024 [19:04<1:09:14,  5.12s/it] 21%|██        | 213/1024 [19:09<1:09:00,  5.10s/it] 21%|██        | 214/1024 [19:14<1:09:04,  5.12s/it] 21%|██        | 215/1024 [19:19<1:08:53,  5.11s/it] 21%|██        | 216/1024 [19:24<1:08:37,  5.10s/it]                                                    {'loss': 1.2952, 'grad_norm': 0.14978610202483297, 'learning_rate': 0.00035804604428746204, 'epoch': 0.44}
 21%|██        | 216/1024 [19:24<1:08:37,  5.10s/it]:::MLLOG {"namespace": "", "time_ms": 1754982374236, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2952, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 1728}}
 21%|██        | 217/1024 [19:30<1:08:33,  5.10s/it]                                                    {'loss': 1.3282, 'grad_norm': 0.12850903393791657, 'learning_rate': 0.0003576692855253213, 'epoch': 0.44}
 21%|██        | 217/1024 [19:30<1:08:33,  5.10s/it] 21%|██▏       | 218/1024 [19:35<1:08:45,  5.12s/it] 21%|██▏       | 219/1024 [19:40<1:08:34,  5.11s/it] 21%|██▏       | 220/1024 [19:45<1:08:41,  5.13s/it] 22%|██▏       | 221/1024 [19:50<1:08:24,  5.11s/it] 22%|██▏       | 222/1024 [19:55<1:08:14,  5.11s/it] 22%|██▏       | 223/1024 [20:00<1:07:56,  5.09s/it] 22%|██▏       | 224/1024 [20:05<1:07:42,  5.08s/it] 22%|██▏       | 225/1024 [20:10<1:07:58,  5.10s/it] 22%|██▏       | 226/1024 [20:16<1:08:10,  5.13s/it] 22%|██▏       | 227/1024 [20:21<1:08:16,  5.14s/it] 22%|██▏       | 228/1024 [20:26<1:07:45,  5.11s/it] 22%|██▏       | 229/1024 [20:31<1:07:23,  5.09s/it] 22%|██▏       | 230/1024 [20:36<1:07:12,  5.08s/it] 23%|██▎       | 231/1024 [20:41<1:07:04,  5.08s/it] 23%|██▎       | 232/1024 [20:46<1:06:54,  5.07s/it] 23%|██▎       | 233/1024 [20:51<1:07:10,  5.10s/it] 23%|██▎       | 234/1024 [20:56<1:07:07,  5.10s/it] 23%|██▎       | 235/1024 [21:01<1:06:56,  5.09s/it] 23%|██▎       | 236/1024 [21:06<1:06:47,  5.09s/it] 23%|██▎       | 237/1024 [21:11<1:06:38,  5.08s/it] 23%|██▎       | 238/1024 [21:17<1:06:57,  5.11s/it] 23%|██▎       | 239/1024 [21:22<1:06:38,  5.09s/it] 23%|██▎       | 240/1024 [21:27<1:06:25,  5.08s/it]                                                    {'loss': 1.2862, 'grad_norm': 0.22692067826114098, 'learning_rate': 0.00034860159042702436, 'epoch': 0.49}
 23%|██▎       | 240/1024 [21:27<1:06:25,  5.08s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:01<00:15,  1.32it/s][A
 14%|█▎        | 3/22 [00:02<00:20,  1.06s/it][A
 18%|█▊        | 4/22 [00:04<00:22,  1.22s/it][A
 23%|██▎       | 5/22 [00:05<00:22,  1.32s/it][A
 27%|██▋       | 6/22 [00:07<00:22,  1.39s/it][A
 32%|███▏      | 7/22 [00:09<00:21,  1.43s/it][A
 36%|███▋      | 8/22 [00:10<00:20,  1.46s/it][A
 41%|████      | 9/22 [00:12<00:19,  1.47s/it][A
 45%|████▌     | 10/22 [00:13<00:17,  1.48s/it][A
 50%|█████     | 11/22 [00:15<00:16,  1.49s/it][A
 55%|█████▍    | 12/22 [00:16<00:14,  1.49s/it][A
 59%|█████▉    | 13/22 [00:18<00:13,  1.50s/it][A
 64%|██████▎   | 14/22 [00:19<00:11,  1.50s/it][A
 68%|██████▊   | 15/22 [00:21<00:10,  1.50s/it][A
 73%|███████▎  | 16/22 [00:22<00:09,  1.50s/it][A
 77%|███████▋  | 17/22 [00:24<00:07,  1.51s/it][A
 82%|████████▏ | 18/22 [00:25<00:06,  1.51s/it][A
 86%|████████▋ | 19/22 [00:27<00:04,  1.51s/it][A
 91%|█████████ | 20/22 [00:28<00:03,  1.51s/it][A
 95%|█████████▌| 21/22 [00:30<00:01,  1.51s/it][A
100%|██████████| 22/22 [00:31<00:00,  1.50s/it][A                                                    
                                               [A{'eval_loss': 0.9313926696777344, 'eval_runtime': 33.1283, 'eval_samples_per_second': 5.222, 'eval_steps_per_second': 0.664, 'epoch': 0.49}
 23%|██▎       | 240/1024 [22:00<1:06:25,  5.08s/it]
100%|██████████| 22/22 [00:31<00:00,  1.50s/it][A
                                               [A:::MLLOG {"namespace": "", "time_ms": 1754982529707, "event_type": "INTERVAL_END", "key": "block_stop", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 174, "samples_count": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1754982529707, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9313926696777344, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 179, "samples_count": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1754982529707, "event_type": "INTERVAL_START", "key": "block_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 184, "samples_count": 240}}
 24%|██▎       | 241/1024 [22:05<3:16:06, 15.03s/it]                                                    {'loss': 1.2915, 'grad_norm': 0.11424520990956995, 'learning_rate': 0.00034819022507099186, 'epoch': 0.49}
 24%|██▎       | 241/1024 [22:05<3:16:06, 15.03s/it] 24%|██▎       | 242/1024 [22:10<2:37:01, 12.05s/it] 24%|██▎       | 243/1024 [22:15<2:09:27,  9.95s/it] 24%|██▍       | 244/1024 [22:20<1:50:13,  8.48s/it] 24%|██▍       | 245/1024 [22:25<1:36:48,  7.46s/it] 24%|██▍       | 246/1024 [22:30<1:27:27,  6.75s/it] 24%|██▍       | 247/1024 [22:35<1:21:02,  6.26s/it] 24%|██▍       | 248/1024 [22:41<1:16:24,  5.91s/it] 24%|██▍       | 249/1024 [22:46<1:12:58,  5.65s/it] 24%|██▍       | 250/1024 [22:51<1:10:35,  5.47s/it] 25%|██▍       | 251/1024 [22:56<1:08:56,  5.35s/it] 25%|██▍       | 252/1024 [23:01<1:07:40,  5.26s/it] 25%|██▍       | 253/1024 [23:06<1:06:55,  5.21s/it] 25%|██▍       | 254/1024 [23:11<1:06:15,  5.16s/it] 25%|██▍       | 255/1024 [23:16<1:05:47,  5.13s/it] 25%|██▌       | 256/1024 [23:21<1:05:26,  5.11s/it] 25%|██▌       | 257/1024 [23:26<1:05:13,  5.10s/it] 25%|██▌       | 258/1024 [23:31<1:05:11,  5.11s/it] 25%|██▌       | 259/1024 [23:36<1:04:59,  5.10s/it] 25%|██▌       | 260/1024 [23:41<1:05:01,  5.11s/it] 25%|██▌       | 261/1024 [23:47<1:04:53,  5.10s/it] 26%|██▌       | 262/1024 [23:52<1:05:04,  5.12s/it] 26%|██▌       | 263/1024 [23:57<1:05:02,  5.13s/it] 26%|██▌       | 264/1024 [24:02<1:04:55,  5.13s/it]                                                    {'loss': 1.3234, 'grad_norm': 0.10090723127361867, 'learning_rate': 0.00033835185167283157, 'epoch': 0.54}
 26%|██▌       | 264/1024 [24:02<1:04:55,  5.13s/it]:::MLLOG {"namespace": "", "time_ms": 1754982651782, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3234, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 2112}}
 26%|██▌       | 265/1024 [24:07<1:04:37,  5.11s/it]                                                    {'loss': 1.3696, 'grad_norm': 0.14669793667338424, 'learning_rate': 0.0003379081089474134, 'epoch': 0.54}
 26%|██▌       | 265/1024 [24:07<1:04:37,  5.11s/it] 26%|██▌       | 266/1024 [24:12<1:04:18,  5.09s/it] 26%|██▌       | 267/1024 [24:17<1:04:02,  5.08s/it] 26%|██▌       | 268/1024 [24:22<1:03:52,  5.07s/it] 26%|██▋       | 269/1024 [24:27<1:03:44,  5.07s/it] 26%|██▋       | 270/1024 [24:32<1:03:38,  5.06s/it] 26%|██▋       | 271/1024 [24:37<1:03:25,  5.05s/it] 27%|██▋       | 272/1024 [24:42<1:03:39,  5.08s/it] 27%|██▋       | 273/1024 [24:48<1:03:47,  5.10s/it] 27%|██▋       | 274/1024 [24:53<1:03:24,  5.07s/it] 27%|██▋       | 275/1024 [24:58<1:03:30,  5.09s/it] 27%|██▋       | 276/1024 [25:03<1:03:27,  5.09s/it] 27%|██▋       | 277/1024 [25:08<1:03:40,  5.11s/it] 27%|██▋       | 278/1024 [25:13<1:03:22,  5.10s/it] 27%|██▋       | 279/1024 [25:18<1:03:03,  5.08s/it] 27%|██▋       | 280/1024 [25:23<1:02:52,  5.07s/it] 27%|██▋       | 281/1024 [25:28<1:02:42,  5.06s/it] 28%|██▊       | 282/1024 [25:33<1:02:54,  5.09s/it] 28%|██▊       | 283/1024 [25:38<1:02:49,  5.09s/it] 28%|██▊       | 284/1024 [25:44<1:02:35,  5.08s/it] 28%|██▊       | 285/1024 [25:49<1:02:25,  5.07s/it] 28%|██▊       | 286/1024 [25:54<1:02:39,  5.09s/it] 28%|██▊       | 287/1024 [25:59<1:02:26,  5.08s/it] 28%|██▊       | 288/1024 [26:04<1:02:21,  5.08s/it]                                                    {'loss': 1.3124, 'grad_norm': 0.14453261097869552, 'learning_rate': 0.00032735237224725683, 'epoch': 0.59}
 28%|██▊       | 288/1024 [26:04<1:02:21,  5.08s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:01<00:15,  1.33it/s][A
 14%|█▎        | 3/22 [00:03<00:20,  1.07s/it][A
 18%|█▊        | 4/22 [00:04<00:22,  1.22s/it][A
 23%|██▎       | 5/22 [00:06<00:22,  1.33s/it][A
 27%|██▋       | 6/22 [00:07<00:22,  1.39s/it][A
 32%|███▏      | 7/22 [00:09<00:21,  1.43s/it][A
 36%|███▋      | 8/22 [00:10<00:20,  1.45s/it][A
 41%|████      | 9/22 [00:12<00:19,  1.47s/it][A
 45%|████▌     | 10/22 [00:13<00:17,  1.48s/it][A
 50%|█████     | 11/22 [00:15<00:16,  1.48s/it][A
 55%|█████▍    | 12/22 [00:16<00:14,  1.49s/it][A
 59%|█████▉    | 13/22 [00:18<00:13,  1.50s/it][A
 64%|██████▎   | 14/22 [00:19<00:12,  1.50s/it][A
 68%|██████▊   | 15/22 [00:21<00:10,  1.50s/it][A
 73%|███████▎  | 16/22 [00:22<00:09,  1.51s/it][A
 77%|███████▋  | 17/22 [00:24<00:07,  1.50s/it][A
 82%|████████▏ | 18/22 [00:25<00:06,  1.50s/it][A
 86%|████████▋ | 19/22 [00:27<00:04,  1.50s/it][A
 91%|█████████ | 20/22 [00:28<00:03,  1.50s/it][A
 95%|█████████▌| 21/22 [00:30<00:01,  1.50s/it][A
100%|██████████| 22/22 [00:31<00:00,  1.50s/it][A                                                    
                                               [A{'eval_loss': 0.9279321432113647, 'eval_runtime': 33.1067, 'eval_samples_per_second': 5.226, 'eval_steps_per_second': 0.665, 'epoch': 0.59}
 28%|██▊       | 288/1024 [26:37<1:02:21,  5.08s/it]
100%|██████████| 22/22 [00:31<00:00,  1.50s/it][A
                                               [A:::MLLOG {"namespace": "", "time_ms": 1754982806756, "event_type": "INTERVAL_END", "key": "block_stop", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 174, "samples_count": 2304}}
:::MLLOG {"namespace": "", "time_ms": 1754982806756, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9279321432113647, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 179, "samples_count": 2304}}
:::MLLOG {"namespace": "", "time_ms": 1754982806756, "event_type": "INTERVAL_START", "key": "block_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 184, "samples_count": 288}}
 28%|██▊       | 289/1024 [26:42<3:03:56, 15.02s/it]                                                    {'loss': 1.2305, 'grad_norm': 0.11297441532493918, 'learning_rate': 0.0003268786568327291, 'epoch': 0.59}
 28%|██▊       | 289/1024 [26:42<3:03:56, 15.02s/it] 28%|██▊       | 290/1024 [26:47<2:27:19, 12.04s/it] 28%|██▊       | 291/1024 [26:52<2:01:46,  9.97s/it] 29%|██▊       | 292/1024 [26:57<1:43:57,  8.52s/it] 29%|██▊       | 293/1024 [27:02<1:31:06,  7.48s/it] 29%|██▊       | 294/1024 [27:08<1:22:10,  6.75s/it] 29%|██▉       | 295/1024 [27:13<1:15:52,  6.25s/it] 29%|██▉       | 296/1024 [27:18<1:11:26,  5.89s/it] 29%|██▉       | 297/1024 [27:23<1:08:20,  5.64s/it] 29%|██▉       | 298/1024 [27:28<1:06:09,  5.47s/it] 29%|██▉       | 299/1024 [27:33<1:04:38,  5.35s/it] 29%|██▉       | 300/1024 [27:38<1:03:30,  5.26s/it] 29%|██▉       | 301/1024 [27:43<1:02:43,  5.20s/it] 29%|██▉       | 302/1024 [27:48<1:02:00,  5.15s/it] 30%|██▉       | 303/1024 [27:53<1:01:34,  5.12s/it] 30%|██▉       | 304/1024 [27:58<1:01:30,  5.13s/it] 30%|██▉       | 305/1024 [28:03<1:01:08,  5.10s/it] 30%|██▉       | 306/1024 [28:08<1:00:56,  5.09s/it] 30%|██▉       | 307/1024 [28:14<1:01:27,  5.14s/it] 30%|███       | 308/1024 [28:19<1:01:05,  5.12s/it] 30%|███       | 309/1024 [28:24<1:00:50,  5.11s/it] 30%|███       | 310/1024 [28:29<1:00:51,  5.11s/it] 30%|███       | 311/1024 [28:34<1:00:32,  5.09s/it] 30%|███       | 312/1024 [28:39<1:00:20,  5.09s/it]                                                    {'loss': 1.302, 'grad_norm': 0.12277982367917166, 'learning_rate': 0.00031566275928233116, 'epoch': 0.64}
 30%|███       | 312/1024 [28:39<1:00:20,  5.09s/it]:::MLLOG {"namespace": "", "time_ms": 1754982928750, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.302, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 2496}}
 31%|███       | 313/1024 [28:44<1:00:21,  5.09s/it]                                                    {'loss': 1.2983, 'grad_norm': 0.11632362936432779, 'learning_rate': 0.0003151616382835691, 'epoch': 0.64}
 31%|███       | 313/1024 [28:44<1:00:21,  5.09s/it] 31%|███       | 314/1024 [28:49<1:00:08,  5.08s/it] 31%|███       | 315/1024 [28:54<59:55,  5.07s/it]   31%|███       | 316/1024 [28:59<59:47,  5.07s/it] 31%|███       | 317/1024 [29:04<1:00:15,  5.11s/it] 31%|███       | 318/1024 [29:09<59:53,  5.09s/it]   31%|███       | 319/1024 [29:15<59:58,  5.10s/it] 31%|███▏      | 320/1024 [29:20<59:48,  5.10s/it] 31%|███▏      | 321/1024 [29:25<59:36,  5.09s/it] 31%|███▏      | 322/1024 [29:30<59:23,  5.08s/it] 32%|███▏      | 323/1024 [29:35<59:15,  5.07s/it] 32%|███▏      | 324/1024 [29:40<59:00,  5.06s/it] 32%|███▏      | 325/1024 [29:45<58:56,  5.06s/it] 32%|███▏      | 326/1024 [29:50<59:03,  5.08s/it] 32%|███▏      | 327/1024 [29:55<58:50,  5.06s/it] 32%|███▏      | 328/1024 [30:00<58:35,  5.05s/it] 32%|███▏      | 329/1024 [30:05<58:53,  5.08s/it] 32%|███▏      | 330/1024 [30:10<58:40,  5.07s/it] 32%|███▏      | 331/1024 [30:16<58:54,  5.10s/it] 32%|███▏      | 332/1024 [30:21<58:43,  5.09s/it] 33%|███▎      | 333/1024 [30:26<58:32,  5.08s/it] 33%|███▎      | 334/1024 [30:31<58:21,  5.07s/it] 33%|███▎      | 335/1024 [30:36<58:23,  5.09s/it] 33%|███▎      | 336/1024 [30:41<58:12,  5.08s/it]                                                  {'loss': 1.3008, 'grad_norm': 0.09864597602354794, 'learning_rate': 0.00030334635980353, 'epoch': 0.69}
 33%|███▎      | 336/1024 [30:41<58:12,  5.08s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:01<00:15,  1.33it/s][A
 14%|█▎        | 3/22 [00:02<00:20,  1.06s/it][A
 18%|█▊        | 4/22 [00:04<00:21,  1.22s/it][A
 23%|██▎       | 5/22 [00:05<00:22,  1.32s/it][A
 27%|██▋       | 6/22 [00:07<00:22,  1.38s/it][A
 32%|███▏      | 7/22 [00:09<00:21,  1.43s/it][A
 36%|███▋      | 8/22 [00:10<00:20,  1.45s/it][A
 41%|████      | 9/22 [00:12<00:19,  1.46s/it][A
 45%|████▌     | 10/22 [00:13<00:17,  1.48s/it][A
 50%|█████     | 11/22 [00:15<00:16,  1.49s/it][A
 55%|█████▍    | 12/22 [00:16<00:14,  1.49s/it][A
 59%|█████▉    | 13/22 [00:18<00:13,  1.49s/it][A
 64%|██████▎   | 14/22 [00:19<00:11,  1.50s/it][A
 68%|██████▊   | 15/22 [00:21<00:10,  1.51s/it][A
 73%|███████▎  | 16/22 [00:22<00:09,  1.50s/it][A
 77%|███████▋  | 17/22 [00:24<00:07,  1.50s/it][A
 82%|████████▏ | 18/22 [00:25<00:06,  1.51s/it][A
 86%|████████▋ | 19/22 [00:27<00:04,  1.50s/it][A
 91%|█████████ | 20/22 [00:28<00:02,  1.50s/it][A
 95%|█████████▌| 21/22 [00:30<00:01,  1.50s/it][A
100%|██████████| 22/22 [00:31<00:00,  1.50s/it][A                                                  
                                               [A{'eval_loss': 0.9239360094070435, 'eval_runtime': 33.0351, 'eval_samples_per_second': 5.237, 'eval_steps_per_second': 0.666, 'epoch': 0.69}
 33%|███▎      | 336/1024 [31:14<58:12,  5.08s/it]
100%|██████████| 22/22 [00:31<00:00,  1.50s/it][A
                                               [A:::MLLOG {"namespace": "", "time_ms": 1754983083704, "event_type": "INTERVAL_END", "key": "block_stop", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 174, "samples_count": 2688}}
:::MLLOG {"namespace": "", "time_ms": 1754983083704, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9239360094070435, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 179, "samples_count": 2688}}
:::MLLOG {"namespace": "", "time_ms": 1754983083704, "event_type": "INTERVAL_START", "key": "block_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 184, "samples_count": 336}}
:::MLLOG {"namespace": "", "time_ms": 1754983083704, "event_type": "INTERVAL_END", "key": "run_stop", "value": 0.9239360094070435, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 195, "samples_count": 2688, "status": "success"}}
 33%|███▎      | 337/1024 [31:19<2:51:50, 15.01s/it]                                                    {'loss': 1.2962, 'grad_norm': 0.12426326141841897, 'learning_rate': 0.0003028205488386443, 'epoch': 0.69}
 33%|███▎      | 337/1024 [31:19<2:51:50, 15.01s/it]                                                    {'train_runtime': 1880.6239, 'train_samples_per_second': 4.356, 'train_steps_per_second': 0.545, 'train_loss': 1.3778206987267785, 'epoch': 0.69}
 33%|███▎      | 337/1024 [31:19<2:51:50, 15.01s/it] 33%|███▎      | 337/1024 [31:19<1:03:51,  5.58s/it]
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33m2025-08-11_23-45-04---llama2-70b-fused-qkv-mlperf[0m at: [34mhttps://wandb.ai/vchua/mlperf-lora/runs/2025-08-11_23-45-04---llama2-70b-fused-qkv-mlperf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250811_234648-2025-08-11_23-45-04---llama2-70b-fused-qkv-mlperf/logs[0m
