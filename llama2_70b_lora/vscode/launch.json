{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "llama2-70b-lora-sft",
            "type": "debugpy",
            "request": "launch",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "PYTHONPATH": "/home/shadeform/work/dev/sf-250812-cust-mlperf/quantized-training"
            },
            "cwd": "${workspaceFolder}/mlperf-training/llama2_70b_lora/",
            "program": "scripts/train.py",
            "args": [
                        "--dataset_path", "../../scrolls_gov_report_preprocessed_mlperf_2/data/",
                        "--model_path", "meta-llama/Llama-2-7b-hf", 
                        // "../../../models/llama2-70b-fused-qkv-mlperf",
                        "--max_seq_len", "8192",
                        "--bf16", "True",
                        // "--wandb",
                        "--logging_steps", "1",
                        "--eval_steps", "48", // to reduce
                        "--output_dir", "./debug_dryrun/llama-70b_scrolls_gov_report_r16",
                        "--per_device_train_batch_size", "1",
                        "--gradient_accumulation_steps", "1",
                        "--lr_scheduler_type", "cosine",
                        "--learning_rate", "4e-4",
                        "--weight_decay", "0.0001",
                        "--warmup_ratio", "0",
                        "--max_grad_norm", "0.3",
                        "--use_gradient_checkpointing", "True",
                        "--target_eval_loss", "0.925",
                        "--use_peft_lora", "True",
                        "--lora_r", "16",
                        "--lora_alpha", "32",
                        "--lora_dropout", "0.1",
                        "--max_steps", "1024",
                        // "--no_use_flash_attn",
                        "--use_flash_attn",
                        "--seed", "1234",
                        "--lora_target_modules", "qkv_proj,o_proj",
                        
            ]
        },
        {
            "name": "Python Debugger: Current File",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal"
        }
    ]
}