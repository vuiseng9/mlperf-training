[2025-08-10 20:57:36,370] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-10 20:57:38,250] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
W0810 20:57:39.079000 163016 site-packages/torch/distributed/run.py:766] 
W0810 20:57:39.079000 163016 site-packages/torch/distributed/run.py:766] *****************************************
W0810 20:57:39.079000 163016 site-packages/torch/distributed/run.py:766] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0810 20:57:39.079000 163016 site-packages/torch/distributed/run.py:766] *****************************************
[2025-08-10 20:57:44,426] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-10 20:57:46,113] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-10 20:57:46,329] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-10 20:57:46,347] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-10 20:57:46,834] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-10 20:57:46,877] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-10 20:57:46,999] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-10 20:57:47,003] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-10 20:57:47,064] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-10 20:57:47,090] [INFO] [real_accelerator.py:254:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2025-08-10 20:57:48,042] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-10 20:57:48,063] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-10 20:57:48,601] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-10 20:57:48,615] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-10 20:57:48,776] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-10 20:57:48,785] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-10 20:57:48,790] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-10 20:57:48,803] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-10 20:57:48,803] [INFO] [comm.py:852:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2025-08-10 20:57:48,904] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-10 20:57:48,919] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-10 20:57:48,923] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-10 20:57:48,927] [INFO] [logging.py:107:log_dist] [Rank -1] [TorchCheckpointEngine] Initialized with serialization = False
[2025-08-10 20:57:48,941] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-10 20:57:48,947] [INFO] [comm.py:821:init_distributed] cdb=None
[2025-08-10 20:57:50,843] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-10 20:57:50,845] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-10 20:57:50,846] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-10 20:57:50,854] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-10 20:57:50,856] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-10 20:57:50,858] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-10 20:57:50,862] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-10 20:57:50,869] [INFO] [config.py:684:__init__] Config mesh_device None world_size = 8
[2025-08-10 20:57:53,288] [INFO] [partition_parameters.py:366:__exit__] finished initializing model - num_params = 563, num_elems = 68.98B
Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:   0%|          | 0/29 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 4/29 [00:00<00:00, 39.59it/s]Loading checkpoint shards:  14%|█▍        | 4/29 [00:00<00:00, 32.82it/s]Loading checkpoint shards:  14%|█▍        | 4/29 [00:00<00:00, 35.94it/s]Loading checkpoint shards:  17%|█▋        | 5/29 [00:00<00:00, 41.15it/s]Loading checkpoint shards:  17%|█▋        | 5/29 [00:00<00:00, 43.92it/s]Loading checkpoint shards:  14%|█▍        | 4/29 [00:00<00:00, 37.24it/s]Loading checkpoint shards:  14%|█▍        | 4/29 [00:00<00:00, 34.79it/s]Loading checkpoint shards:   3%|▎         | 1/29 [00:00<00:27,  1.01it/s]Loading checkpoint shards:   7%|▋         | 2/29 [00:01<00:26,  1.02it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:08,  2.59it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:07,  2.63it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:07,  2.63it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:08,  2.61it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:02<00:08,  2.60it/s]Loading checkpoint shards:  10%|█         | 3/29 [00:03<00:27,  1.04s/it]Loading checkpoint shards:  14%|█▍        | 4/29 [00:04<00:26,  1.07s/it]Loading checkpoint shards:  34%|███▍      | 10/29 [00:04<00:11,  1.69it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:04<00:11,  1.68it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:04<00:10,  1.77it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:04<00:11,  1.69it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:04<00:10,  1.78it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:04<00:11,  1.69it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:04<00:11,  1.69it/s]Loading checkpoint shards:  17%|█▋        | 5/29 [00:05<00:25,  1.08s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [00:05<00:12,  1.45it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:05<00:12,  1.45it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:05<00:12,  1.45it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:05<00:12,  1.44it/s]Loading checkpoint shards:  38%|███▊      | 11/29 [00:05<00:12,  1.45it/s]Loading checkpoint shards:  21%|██        | 6/29 [00:06<00:24,  1.07s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [00:07<00:13,  1.30it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:07<00:13,  1.30it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:07<00:13,  1.30it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:07<00:11,  1.42it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:07<00:11,  1.42it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:07<00:13,  1.30it/s]Loading checkpoint shards:  41%|████▏     | 12/29 [00:07<00:13,  1.30it/s]Loading checkpoint shards:  24%|██▍       | 7/29 [00:07<00:23,  1.08s/it]Loading checkpoint shards:  45%|████▍     | 13/29 [00:08<00:13,  1.18it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:08<00:13,  1.18it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:08<00:13,  1.17it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:08<00:12,  1.30it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:08<00:13,  1.18it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:08<00:13,  1.18it/s]Loading checkpoint shards:  28%|██▊       | 8/29 [00:08<00:23,  1.12s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [00:09<00:13,  1.10it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:09<00:13,  1.10it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:09<00:12,  1.23it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:09<00:13,  1.10it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:09<00:13,  1.10it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:09<00:12,  1.21it/s]Loading checkpoint shards:  48%|████▊     | 14/29 [00:09<00:13,  1.10it/s]Loading checkpoint shards:  31%|███       | 9/29 [00:09<00:22,  1.13s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:10<00:13,  1.04it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:10<00:13,  1.04it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:10<00:12,  1.17it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:10<00:13,  1.04it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:10<00:12,  1.13it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:10<00:13,  1.04it/s]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:10<00:13,  1.04it/s]Loading checkpoint shards:  34%|███▍      | 10/29 [00:10<00:21,  1.11s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:11<00:13,  1.01s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:11<00:13,  1.01s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:11<00:13,  1.01s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:11<00:12,  1.06it/s]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:11<00:11,  1.09it/s]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:11<00:13,  1.01s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:11<00:13,  1.01s/it]Loading checkpoint shards:  38%|███▊      | 11/29 [00:11<00:19,  1.10s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:12<00:12,  1.03s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:12<00:12,  1.03s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:12<00:12,  1.03s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:12<00:11,  1.06it/s]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:12<00:11,  1.03it/s]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:12<00:12,  1.03s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:12<00:12,  1.03s/it]Loading checkpoint shards:  41%|████▏     | 12/29 [00:12<00:18,  1.08s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:13<00:11,  1.03s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:13<00:11,  1.03s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:13<00:11,  1.03s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:13<00:10,  1.03it/s]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:13<00:11,  1.03s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:13<00:11,  1.03s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:13<00:10,  1.01it/s]Loading checkpoint shards:  45%|████▍     | 13/29 [00:14<00:17,  1.10s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:14<00:10,  1.05s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:14<00:10,  1.05s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:14<00:10,  1.05s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:14<00:10,  1.02s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:14<00:10,  1.05s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:14<00:10,  1.00s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:14<00:10,  1.05s/it]Loading checkpoint shards:  48%|████▊     | 14/29 [00:15<00:16,  1.12s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:15<00:09,  1.07s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:15<00:09,  1.07s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:15<00:09,  1.07s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:15<00:09,  1.05s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:15<00:09,  1.03s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:15<00:09,  1.07s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:15<00:09,  1.07s/it]Loading checkpoint shards:  52%|█████▏    | 15/29 [00:16<00:15,  1.10s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:17<00:08,  1.12s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:17<00:08,  1.12s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:17<00:08,  1.10s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:17<00:08,  1.12s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:17<00:08,  1.08s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:17<00:08,  1.12s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:17<00:08,  1.12s/it]Loading checkpoint shards:  55%|█████▌    | 16/29 [00:17<00:14,  1.12s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:18<00:07,  1.11s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:18<00:07,  1.11s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:18<00:07,  1.11s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:18<00:07,  1.10s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:18<00:07,  1.11s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:18<00:07,  1.09s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:18<00:07,  1.11s/it]Loading checkpoint shards:  59%|█████▊    | 17/29 [00:18<00:13,  1.11s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:19<00:06,  1.09s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:19<00:06,  1.09s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:19<00:06,  1.09s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:19<00:06,  1.08s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:19<00:06,  1.09s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:19<00:06,  1.08s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:19<00:06,  1.09s/it]Loading checkpoint shards:  62%|██████▏   | 18/29 [00:19<00:12,  1.11s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:20<00:05,  1.09s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:20<00:05,  1.08s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:20<00:05,  1.09s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:20<00:05,  1.09s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:20<00:05,  1.09s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:20<00:05,  1.09s/it]Loading checkpoint shards:  83%|████████▎ | 24/29 [00:20<00:05,  1.08s/it]Loading checkpoint shards:  66%|██████▌   | 19/29 [00:20<00:11,  1.12s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:21<00:04,  1.11s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:21<00:04,  1.11s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:21<00:04,  1.11s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:21<00:04,  1.10s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:21<00:04,  1.10s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:21<00:04,  1.11s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:21<00:04,  1.11s/it]Loading checkpoint shards:  69%|██████▉   | 20/29 [00:21<00:10,  1.12s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:22<00:03,  1.14s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:22<00:03,  1.14s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:22<00:03,  1.14s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:22<00:03,  1.14s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:22<00:03,  1.14s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:22<00:03,  1.14s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:22<00:03,  1.14s/it]Loading checkpoint shards:  72%|███████▏  | 21/29 [00:23<00:08,  1.12s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:23<00:02,  1.12s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:23<00:02,  1.12s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:23<00:02,  1.12s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:23<00:02,  1.12s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:23<00:02,  1.12s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:23<00:02,  1.12s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:23<00:02,  1.12s/it]Loading checkpoint shards:  76%|███████▌  | 22/29 [00:24<00:07,  1.10s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:24<00:01,  1.09s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:24<00:01,  1.09s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:24<00:01,  1.09s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:24<00:01,  1.09s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:24<00:01,  1.09s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:24<00:01,  1.09s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:24<00:01,  1.09s/it]Loading checkpoint shards:  79%|███████▉  | 23/29 [00:25<00:06,  1.10s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.12it/s]

Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.12it/s]


Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.12it/s]Loading checkpoint shards: 100%|██████████| 29/29 [00:25<00:00,  1.12it/s]

Loading checkpoint shards:  83%|████████▎ | 24/29 [00:26<00:05,  1.14s/it]Loading checkpoint shards:  86%|████████▌ | 25/29 [00:27<00:04,  1.13s/it]Loading checkpoint shards:  90%|████████▉ | 26/29 [00:28<00:03,  1.13s/it]Loading checkpoint shards:  93%|█████████▎| 27/29 [00:29<00:02,  1.12s/it]Loading checkpoint shards:  97%|█████████▋| 28/29 [00:31<00:01,  1.15s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:31<00:00,  1.06s/it]Loading checkpoint shards: 100%|██████████| 29/29 [00:31<00:00,  1.10s/it]
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
PeftModelForCausalLM(
  (base_model): LoraModel(
    (model): CustomLlamaForCausalLM(
      (model): LlamaModel(
        (embed_tokens): Embedding(32000, 8192)
        (layers): ModuleList(
          (0-79): 80 x LlamaDecoderLayer(
            (self_attn): LlamaFlashAttention2(
              (qkv_proj): lora.Linear(
                (base_layer): Linear(in_features=8192, out_features=10240, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=8192, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=10240, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (o_proj): lora.Linear(
                (base_layer): Linear(in_features=8192, out_features=8192, bias=False)
                (lora_dropout): ModuleDict(
                  (default): Dropout(p=0.1, inplace=False)
                )
                (lora_A): ModuleDict(
                  (default): Linear(in_features=8192, out_features=16, bias=False)
                )
                (lora_B): ModuleDict(
                  (default): Linear(in_features=16, out_features=8192, bias=False)
                )
                (lora_embedding_A): ParameterDict()
                (lora_embedding_B): ParameterDict()
                (lora_magnitude_vector): ModuleDict()
              )
              (rotary_emb): LlamaRotaryEmbedding()
            )
            (mlp): LlamaMLP(
              (gate_proj): Linear(in_features=8192, out_features=28672, bias=False)
              (up_proj): Linear(in_features=8192, out_features=28672, bias=False)
              (down_proj): Linear(in_features=28672, out_features=8192, bias=False)
              (act_fn): SiLU()
            )
            (input_layernorm): LlamaRMSNorm()
            (post_attention_layernorm): LlamaRMSNorm()
          )
        )
        (norm): LlamaRMSNorm()
      )
      (lm_head): Linear(in_features=8192, out_features=32000, bias=False)
    )
  )
)
trainable params: 44,564,480 || all params: 69,021,212,672 || trainable%: 0.0646
Parameter Offload - Persistent parameters statistics: param_count = 161, numel = 1318912
wandb: Currently logged in as: vchua to https://api.wandb.ai. Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.21.1
wandb: Run data is saved locally in /home/shadeform/work/dev/sf-250810-sxm/mlperf-training/llama2_70b_lora/wandb/run-20250810_205832-2025-08-10_20-57-46---llama2-70b-fused-qkv-mlperf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run 2025-08-10_20-57-46---llama2-70b-fused-qkv-mlperf
wandb: ⭐️ View project at https://wandb.ai/vchua/mlperf-lora
wandb: 🚀 View run at https://wandb.ai/vchua/mlperf-lora/runs/2025-08-10_20-57-46---llama2-70b-fused-qkv-mlperf
:::MLLOG {"namespace": "", "time_ms": 1754884713658, "event_type": "POINT_IN_TIME", "key": "cache_clear", "value": "True", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 94}}
:::MLLOG {"namespace": "", "time_ms": 1754884713659, "event_type": "POINT_IN_TIME", "key": "submission_benchmark", "value": "llama2_70b_lora", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 97}}
:::MLLOG {"namespace": "", "time_ms": 1754884713659, "event_type": "POINT_IN_TIME", "key": "submission_division", "value": "closed", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 101}}
:::MLLOG {"namespace": "", "time_ms": 1754884713659, "event_type": "POINT_IN_TIME", "key": "submission_org", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 105}}
:::MLLOG {"namespace": "", "time_ms": 1754884713660, "event_type": "POINT_IN_TIME", "key": "submission_platform", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 108}}
:::MLLOG {"namespace": "", "time_ms": 1754884713660, "event_type": "POINT_IN_TIME", "key": "submission_poc_name", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 112}}
:::MLLOG {"namespace": "", "time_ms": 1754884713660, "event_type": "POINT_IN_TIME", "key": "submission_poc_email", "value": "referece", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 116}}
:::MLLOG {"namespace": "", "time_ms": 1754884713660, "event_type": "POINT_IN_TIME", "key": "submission_status", "value": "onprem", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 120}}
:::MLLOG {"namespace": "", "time_ms": 1754884713661, "event_type": "POINT_IN_TIME", "key": "global_batch_size", "value": 8, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 124}}
:::MLLOG {"namespace": "", "time_ms": 1754884713661, "event_type": "POINT_IN_TIME", "key": "train_samples", "value": 3901, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 128}}
:::MLLOG {"namespace": "", "time_ms": 1754884713661, "event_type": "POINT_IN_TIME", "key": "eval_samples", "value": 173, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 132}}
:::MLLOG {"namespace": "", "time_ms": 1754884713661, "event_type": "POINT_IN_TIME", "key": "seed", "value": 101, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 136}}
:::MLLOG {"namespace": "", "time_ms": 1754884713662, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_warmup_factor", "value": 0.0, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 137}}
:::MLLOG {"namespace": "", "time_ms": 1754884713662, "event_type": "POINT_IN_TIME", "key": "opt_learning_rate_training_steps", "value": 1024, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 138}}
:::MLLOG {"namespace": "", "time_ms": 1754884713662, "event_type": "POINT_IN_TIME", "key": "opt_adamw_weight_decay", "value": 0.0001, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 139}}
:::MLLOG {"namespace": "", "time_ms": 1754884713662, "event_type": "POINT_IN_TIME", "key": "opt_gradient_clip_norm", "value": 0.3, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 140}}
:::MLLOG {"namespace": "", "time_ms": 1754884713663, "event_type": "POINT_IN_TIME", "key": "opt_base_learning_rate", "value": 0.0004, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 141}}
:::MLLOG {"namespace": "", "time_ms": 1754884713663, "event_type": "POINT_IN_TIME", "key": "lora_alpha", "value": 32, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 142}}
:::MLLOG {"namespace": "", "time_ms": 1754884713663, "event_type": "POINT_IN_TIME", "key": "lora_rank", "value": 16, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 143}}
:::MLLOG {"namespace": "", "time_ms": 1754884713663, "event_type": "POINT_IN_TIME", "key": "gradient_accumulation_steps", "value": 1, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 144}}
:::MLLOG {"namespace": "", "time_ms": 1754884713664, "event_type": "INTERVAL_START", "key": "init_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 145}}
:::MLLOG {"namespace": "", "time_ms": 1754884713664, "event_type": "INTERVAL_END", "key": "init_stop", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 147}}
:::MLLOG {"namespace": "", "time_ms": 1754884713664, "event_type": "INTERVAL_START", "key": "run_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 148}}
  0%|          | 0/1024 [00:00<?, ?it/s]  0%|          | 1/1024 [00:21<6:05:33, 21.44s/it]  0%|          | 2/1024 [00:41<5:52:27, 20.69s/it]  0%|          | 3/1024 [01:01<5:45:43, 20.32s/it]  0%|          | 4/1024 [01:21<5:42:45, 20.16s/it]  0%|          | 5/1024 [01:41<5:40:52, 20.07s/it]  1%|          | 6/1024 [02:01<5:39:35, 20.02s/it]  1%|          | 7/1024 [02:21<5:38:49, 19.99s/it]  1%|          | 8/1024 [02:41<5:38:33, 19.99s/it]  1%|          | 9/1024 [03:01<5:38:30, 20.01s/it]  1%|          | 10/1024 [03:21<5:38:11, 20.01s/it]  1%|          | 11/1024 [03:41<5:38:13, 20.03s/it]  1%|          | 12/1024 [04:01<5:37:47, 20.03s/it]  1%|▏         | 13/1024 [04:21<5:37:08, 20.01s/it]  1%|▏         | 14/1024 [04:41<5:36:32, 19.99s/it]  1%|▏         | 15/1024 [05:01<5:36:02, 19.98s/it]  2%|▏         | 16/1024 [05:21<5:35:51, 19.99s/it]  2%|▏         | 17/1024 [05:41<5:35:36, 20.00s/it]  2%|▏         | 18/1024 [06:01<5:35:25, 20.01s/it]  2%|▏         | 19/1024 [06:21<5:34:59, 20.00s/it]  2%|▏         | 20/1024 [06:41<5:34:38, 20.00s/it]  2%|▏         | 21/1024 [07:01<5:34:28, 20.01s/it]  2%|▏         | 22/1024 [07:21<5:34:11, 20.01s/it]  2%|▏         | 23/1024 [07:41<5:33:56, 20.02s/it]  2%|▏         | 24/1024 [08:01<5:33:46, 20.03s/it]                                                   {'loss': 2.2087, 'grad_norm': 0.2864038382446092, 'learning_rate': 0.00039950229122806075, 'epoch': 0.05}
  2%|▏         | 24/1024 [08:01<5:33:46, 20.03s/it]:::MLLOG {"namespace": "", "time_ms": 1754885195040, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 2.2087, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 192}}
  2%|▏         | 25/1024 [08:21<5:33:42, 20.04s/it]                                                   {'loss': 1.4628, 'grad_norm': 0.2616428831245071, 'learning_rate': 0.00039945809133573807, 'epoch': 0.05}
  2%|▏         | 25/1024 [08:21<5:33:42, 20.04s/it]  3%|▎         | 26/1024 [08:41<5:33:28, 20.05s/it]  3%|▎         | 27/1024 [09:01<5:33:04, 20.04s/it]  3%|▎         | 28/1024 [09:21<5:32:49, 20.05s/it]  3%|▎         | 29/1024 [09:41<5:32:15, 20.04s/it]  3%|▎         | 30/1024 [10:01<5:31:59, 20.04s/it]  3%|▎         | 31/1024 [10:21<5:31:35, 20.04s/it]  3%|▎         | 32/1024 [10:41<5:31:12, 20.03s/it]  3%|▎         | 33/1024 [11:01<5:31:00, 20.04s/it]  3%|▎         | 34/1024 [11:21<5:30:47, 20.05s/it]  3%|▎         | 35/1024 [11:41<5:30:27, 20.05s/it]  4%|▎         | 36/1024 [12:01<5:29:51, 20.03s/it]  4%|▎         | 37/1024 [12:21<5:29:28, 20.03s/it]  4%|▎         | 38/1024 [12:41<5:28:59, 20.02s/it]  4%|▍         | 39/1024 [13:01<5:28:30, 20.01s/it]  4%|▍         | 40/1024 [13:21<5:28:04, 20.00s/it]  4%|▍         | 41/1024 [13:41<5:27:36, 20.00s/it]  4%|▍         | 42/1024 [14:01<5:27:17, 20.00s/it]  4%|▍         | 43/1024 [14:21<5:26:58, 20.00s/it]  4%|▍         | 44/1024 [14:41<5:26:42, 20.00s/it]  4%|▍         | 45/1024 [15:01<5:26:20, 20.00s/it]  4%|▍         | 46/1024 [15:21<5:26:04, 20.00s/it]  5%|▍         | 47/1024 [15:41<5:25:49, 20.01s/it]  5%|▍         | 48/1024 [16:01<5:25:32, 20.01s/it]                                                   {'loss': 1.3854, 'grad_norm': 0.15642876561724178, 'learning_rate': 0.0003979244034926402, 'epoch': 0.1}
  5%|▍         | 48/1024 [16:01<5:25:32, 20.01s/it]  5%|▍         | 49/1024 [16:21<5:25:07, 20.01s/it]  5%|▍         | 50/1024 [16:41<5:24:51, 20.01s/it]  5%|▍         | 51/1024 [17:01<5:24:31, 20.01s/it]  5%|▌         | 52/1024 [17:21<5:24:17, 20.02s/it]  5%|▌         | 53/1024 [17:41<5:23:44, 20.00s/it]  5%|▌         | 54/1024 [18:01<5:23:29, 20.01s/it]  5%|▌         | 55/1024 [18:21<5:23:05, 20.01s/it]  5%|▌         | 56/1024 [18:41<5:22:33, 19.99s/it]  6%|▌         | 57/1024 [19:01<5:22:15, 20.00s/it]  6%|▌         | 58/1024 [19:21<5:22:07, 20.01s/it]  6%|▌         | 59/1024 [19:41<5:21:41, 20.00s/it]  6%|▌         | 60/1024 [20:01<5:21:35, 20.02s/it]  6%|▌         | 61/1024 [20:21<5:20:52, 19.99s/it]  6%|▌         | 62/1024 [20:41<5:20:40, 20.00s/it]  6%|▌         | 63/1024 [21:01<5:20:20, 20.00s/it]  6%|▋         | 64/1024 [21:21<5:20:03, 20.00s/it]  6%|▋         | 65/1024 [21:41<5:19:41, 20.00s/it]  6%|▋         | 66/1024 [22:01<5:19:12, 19.99s/it]  7%|▋         | 67/1024 [22:21<5:18:56, 20.00s/it]  7%|▋         | 68/1024 [22:41<5:18:30, 19.99s/it]  7%|▋         | 69/1024 [23:01<5:18:12, 19.99s/it]  7%|▋         | 70/1024 [23:21<5:17:54, 19.99s/it]  7%|▋         | 71/1024 [23:41<5:17:46, 20.01s/it]  7%|▋         | 72/1024 [24:01<5:17:30, 20.01s/it]                                                   {'loss': 1.3273, 'grad_norm': 0.1184086524107454, 'learning_rate': 0.0003952739462660042, 'epoch': 0.15}
  7%|▋         | 72/1024 [24:01<5:17:30, 20.01s/it]:::MLLOG {"namespace": "", "time_ms": 1754886155645, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3273, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 576}}
  7%|▋         | 73/1024 [24:21<5:17:11, 20.01s/it]                                                   {'loss': 1.3196, 'grad_norm': 0.14575981824648104, 'learning_rate': 0.0003951404260077057, 'epoch': 0.15}
  7%|▋         | 73/1024 [24:21<5:17:11, 20.01s/it]  7%|▋         | 74/1024 [24:42<5:17:02, 20.02s/it]  7%|▋         | 75/1024 [25:02<5:16:52, 20.03s/it]  7%|▋         | 76/1024 [25:22<5:16:40, 20.04s/it]  8%|▊         | 77/1024 [25:42<5:16:16, 20.04s/it]  8%|▊         | 78/1024 [26:02<5:16:01, 20.04s/it]  8%|▊         | 79/1024 [26:22<5:15:44, 20.05s/it]  8%|▊         | 80/1024 [26:42<5:15:17, 20.04s/it]  8%|▊         | 81/1024 [27:02<5:15:01, 20.04s/it]  8%|▊         | 82/1024 [27:22<5:14:45, 20.05s/it]  8%|▊         | 83/1024 [27:42<5:14:19, 20.04s/it]  8%|▊         | 84/1024 [28:02<5:13:53, 20.04s/it]  8%|▊         | 85/1024 [28:22<5:13:26, 20.03s/it]  8%|▊         | 86/1024 [28:42<5:12:56, 20.02s/it]  8%|▊         | 87/1024 [29:02<5:12:28, 20.01s/it]  9%|▊         | 88/1024 [29:22<5:12:07, 20.01s/it]  9%|▊         | 89/1024 [29:42<5:11:49, 20.01s/it]  9%|▉         | 90/1024 [30:02<5:11:25, 20.01s/it]  9%|▉         | 91/1024 [30:22<5:10:53, 19.99s/it]  9%|▉         | 92/1024 [30:42<5:10:30, 19.99s/it]  9%|▉         | 93/1024 [31:02<5:10:19, 20.00s/it]  9%|▉         | 94/1024 [31:22<5:10:01, 20.00s/it]  9%|▉         | 95/1024 [31:42<5:09:42, 20.00s/it]  9%|▉         | 96/1024 [32:02<5:09:18, 20.00s/it]                                                   {'loss': 1.3161, 'grad_norm': 0.15197815923047472, 'learning_rate': 0.0003915652826055066, 'epoch': 0.2}
  9%|▉         | 96/1024 [32:02<5:09:18, 20.00s/it]  9%|▉         | 97/1024 [32:22<5:08:52, 19.99s/it] 10%|▉         | 98/1024 [32:42<5:08:27, 19.99s/it] 10%|▉         | 99/1024 [33:02<5:08:08, 19.99s/it] 10%|▉         | 100/1024 [33:22<5:07:50, 19.99s/it] 10%|▉         | 101/1024 [33:42<5:07:31, 19.99s/it] 10%|▉         | 102/1024 [34:02<5:07:08, 19.99s/it] 10%|█         | 103/1024 [34:22<5:06:50, 19.99s/it] 10%|█         | 104/1024 [34:42<5:06:35, 20.00s/it] 10%|█         | 105/1024 [35:02<5:06:15, 19.99s/it] 10%|█         | 106/1024 [35:22<5:05:56, 20.00s/it] 10%|█         | 107/1024 [35:42<5:05:19, 19.98s/it] 11%|█         | 108/1024 [36:02<5:05:04, 19.98s/it] 11%|█         | 109/1024 [36:22<5:04:42, 19.98s/it] 11%|█         | 110/1024 [36:42<5:04:28, 19.99s/it] 11%|█         | 111/1024 [37:02<5:04:07, 19.99s/it] 11%|█         | 112/1024 [37:22<5:03:48, 19.99s/it] 11%|█         | 113/1024 [37:42<5:03:29, 19.99s/it] 11%|█         | 114/1024 [38:02<5:03:05, 19.98s/it] 11%|█         | 115/1024 [38:22<5:02:41, 19.98s/it] 11%|█▏        | 116/1024 [38:42<5:02:20, 19.98s/it] 11%|█▏        | 117/1024 [39:02<5:02:08, 19.99s/it] 12%|█▏        | 118/1024 [39:22<5:01:51, 19.99s/it] 12%|█▏        | 119/1024 [39:42<5:01:27, 19.99s/it] 12%|█▏        | 120/1024 [40:02<5:01:03, 19.98s/it]                                                    {'loss': 1.3138, 'grad_norm': 0.2013228681770575, 'learning_rate': 0.00038681851008085183, 'epoch': 0.25}
 12%|█▏        | 120/1024 [40:02<5:01:03, 19.98s/it]:::MLLOG {"namespace": "", "time_ms": 1754887115782, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3138, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 960}}
 12%|█▏        | 121/1024 [40:22<5:00:39, 19.98s/it]                                                    {'loss': 1.3251, 'grad_norm': 0.12491072111424, 'learning_rate': 0.0003865985597669478, 'epoch': 0.25}
 12%|█▏        | 121/1024 [40:22<5:00:39, 19.98s/it] 12%|█▏        | 122/1024 [40:42<5:00:16, 19.97s/it] 12%|█▏        | 123/1024 [41:02<4:59:54, 19.97s/it] 12%|█▏        | 124/1024 [41:22<4:59:44, 19.98s/it] 12%|█▏        | 125/1024 [41:42<4:59:29, 19.99s/it] 12%|█▏        | 126/1024 [42:02<4:59:14, 19.99s/it] 12%|█▏        | 127/1024 [42:22<4:58:59, 20.00s/it] 12%|█▎        | 128/1024 [42:42<4:58:38, 20.00s/it] 13%|█▎        | 129/1024 [43:02<4:58:22, 20.00s/it] 13%|█▎        | 130/1024 [43:22<4:57:51, 19.99s/it] 13%|█▎        | 131/1024 [43:42<4:57:36, 20.00s/it] 13%|█▎        | 132/1024 [44:01<4:57:11, 19.99s/it] 13%|█▎        | 133/1024 [44:21<4:56:46, 19.99s/it] 13%|█▎        | 134/1024 [44:41<4:56:27, 19.99s/it] 13%|█▎        | 135/1024 [45:01<4:56:19, 20.00s/it] 13%|█▎        | 136/1024 [45:21<4:55:48, 19.99s/it] 13%|█▎        | 137/1024 [45:41<4:55:28, 19.99s/it] 13%|█▎        | 138/1024 [46:01<4:54:58, 19.98s/it] 14%|█▎        | 139/1024 [46:21<4:54:37, 19.97s/it] 14%|█▎        | 140/1024 [46:41<4:54:32, 19.99s/it] 14%|█▍        | 141/1024 [47:02<4:54:46, 20.03s/it] 14%|█▍        | 142/1024 [47:22<4:54:20, 20.02s/it] 14%|█▍        | 143/1024 [47:42<4:53:54, 20.02s/it] 14%|█▍        | 144/1024 [48:01<4:53:17, 20.00s/it]                                                    {'loss': 1.298, 'grad_norm': 0.1066913531599974, 'learning_rate': 0.0003810593518636238, 'epoch': 0.3}
 14%|█▍        | 144/1024 [48:01<4:53:17, 20.00s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:06<01:04,  3.20s/it][A
 14%|█▎        | 3/22 [00:12<01:26,  4.55s/it][A
 18%|█▊        | 4/22 [00:19<01:35,  5.30s/it][A
 23%|██▎       | 5/22 [00:25<01:36,  5.68s/it][A
 27%|██▋       | 6/22 [00:32<01:34,  5.93s/it][A
 32%|███▏      | 7/22 [00:38<01:31,  6.09s/it][A
 36%|███▋      | 8/22 [00:45<01:27,  6.22s/it][A
 41%|████      | 9/22 [00:51<01:21,  6.29s/it][A
 45%|████▌     | 10/22 [00:58<01:16,  6.36s/it][A
 50%|█████     | 11/22 [01:04<01:10,  6.37s/it][A
 55%|█████▍    | 12/22 [01:10<01:03,  6.40s/it][A
 59%|█████▉    | 13/22 [01:17<00:57,  6.43s/it][A
 64%|██████▎   | 14/22 [01:23<00:51,  6.42s/it][A
 68%|██████▊   | 15/22 [01:30<00:45,  6.46s/it][A
 73%|███████▎  | 16/22 [01:36<00:38,  6.45s/it][A
 77%|███████▋  | 17/22 [01:43<00:32,  6.44s/it][A
 82%|████████▏ | 18/22 [01:49<00:25,  6.47s/it][A
 86%|████████▋ | 19/22 [01:56<00:19,  6.45s/it][A
 91%|█████████ | 20/22 [02:02<00:12,  6.46s/it][A
 95%|█████████▌| 21/22 [02:09<00:06,  6.45s/it][A
100%|██████████| 22/22 [02:15<00:00,  6.46s/it][A                                                    
                                               [A{'eval_loss': 0.9449393153190613, 'eval_runtime': 141.9416, 'eval_samples_per_second': 1.219, 'eval_steps_per_second': 0.155, 'epoch': 0.3}
 14%|█▍        | 144/1024 [50:23<4:53:17, 20.00s/it]
100%|██████████| 22/22 [02:15<00:00,  6.46s/it][A
                                               [A 14%|█▍        | 145/1024 [50:43<15:17:03, 62.60s/it] 14%|█▍        | 146/1024 [51:03<12:09:01, 49.82s/it] 14%|█▍        | 147/1024 [51:23<9:57:20, 40.87s/it]  14%|█▍        | 148/1024 [51:43<8:25:10, 34.60s/it] 15%|█▍        | 149/1024 [52:03<7:20:33, 30.21s/it] 15%|█▍        | 150/1024 [52:23<6:35:23, 27.14s/it] 15%|█▍        | 151/1024 [52:43<6:03:34, 24.99s/it] 15%|█▍        | 152/1024 [53:03<5:41:16, 23.48s/it] 15%|█▍        | 153/1024 [53:23<5:25:42, 22.44s/it] 15%|█▌        | 154/1024 [53:43<5:14:37, 21.70s/it] 15%|█▌        | 155/1024 [54:03<5:06:47, 21.18s/it] 15%|█▌        | 156/1024 [54:23<5:01:30, 20.84s/it] 15%|█▌        | 157/1024 [54:43<4:57:30, 20.59s/it] 15%|█▌        | 158/1024 [55:03<4:54:35, 20.41s/it] 16%|█▌        | 159/1024 [55:23<4:52:26, 20.29s/it] 16%|█▌        | 160/1024 [55:43<4:50:45, 20.19s/it] 16%|█▌        | 161/1024 [56:03<4:49:40, 20.14s/it] 16%|█▌        | 162/1024 [56:23<4:48:43, 20.10s/it] 16%|█▌        | 163/1024 [56:43<4:47:50, 20.06s/it] 16%|█▌        | 164/1024 [57:03<4:47:15, 20.04s/it] 16%|█▌        | 165/1024 [57:23<4:46:37, 20.02s/it] 16%|█▌        | 166/1024 [57:43<4:46:13, 20.02s/it] 16%|█▋        | 167/1024 [58:03<4:45:49, 20.01s/it] 16%|█▋        | 168/1024 [58:23<4:45:22, 20.00s/it]                                                    {'loss': 1.3044, 'grad_norm': 0.1236764217392571, 'learning_rate': 0.0003743190173311902, 'epoch': 0.34}
 16%|█▋        | 168/1024 [58:23<4:45:22, 20.00s/it]:::MLLOG {"namespace": "", "time_ms": 1754888217378, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3044, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 1344}}
 17%|█▋        | 169/1024 [58:43<4:44:59, 20.00s/it]                                                    {'loss': 1.3159, 'grad_norm': 0.40223418050156684, 'learning_rate': 0.0003740173982217423, 'epoch': 0.35}
 17%|█▋        | 169/1024 [58:43<4:44:59, 20.00s/it] 17%|█▋        | 170/1024 [59:03<4:44:36, 20.00s/it] 17%|█▋        | 171/1024 [59:23<4:44:14, 19.99s/it] 17%|█▋        | 172/1024 [59:43<4:43:59, 20.00s/it] 17%|█▋        | 173/1024 [1:00:03<4:43:38, 20.00s/it] 17%|█▋        | 174/1024 [1:00:23<4:43:18, 20.00s/it] 17%|█▋        | 175/1024 [1:00:43<4:42:53, 19.99s/it] 17%|█▋        | 176/1024 [1:01:03<4:42:28, 19.99s/it] 17%|█▋        | 177/1024 [1:01:23<4:42:14, 19.99s/it] 17%|█▋        | 178/1024 [1:01:43<4:41:51, 19.99s/it] 17%|█▋        | 179/1024 [1:02:03<4:41:35, 20.00s/it] 18%|█▊        | 180/1024 [1:02:23<4:41:14, 19.99s/it] 18%|█▊        | 181/1024 [1:02:43<4:41:01, 20.00s/it] 18%|█▊        | 182/1024 [1:03:03<4:40:47, 20.01s/it] 18%|█▊        | 183/1024 [1:03:23<4:40:39, 20.02s/it] 18%|█▊        | 184/1024 [1:03:43<4:40:16, 20.02s/it] 18%|█▊        | 185/1024 [1:04:03<4:39:41, 20.00s/it] 18%|█▊        | 186/1024 [1:04:23<4:39:19, 20.00s/it] 18%|█▊        | 187/1024 [1:04:43<4:39:03, 20.00s/it] 18%|█▊        | 188/1024 [1:05:03<4:38:33, 19.99s/it] 18%|█▊        | 189/1024 [1:05:23<4:38:20, 20.00s/it] 19%|█▊        | 190/1024 [1:05:43<4:37:54, 19.99s/it] 19%|█▊        | 191/1024 [1:06:03<4:37:38, 20.00s/it] 19%|█▉        | 192/1024 [1:06:23<4:37:18, 20.00s/it]                                                      {'loss': 1.3168, 'grad_norm': 0.13758741619122755, 'learning_rate': 0.00036663403294038264, 'epoch': 0.39}
 19%|█▉        | 192/1024 [1:06:23<4:37:18, 20.00s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:06<01:03,  3.20s/it][A
 14%|█▎        | 3/22 [00:12<01:27,  4.59s/it][A
 18%|█▊        | 4/22 [00:19<01:34,  5.26s/it][A
 23%|██▎       | 5/22 [00:25<01:36,  5.67s/it][A
 27%|██▋       | 6/22 [00:32<01:34,  5.94s/it][A
 32%|███▏      | 7/22 [00:38<01:31,  6.12s/it][A
 36%|███▋      | 8/22 [00:45<01:27,  6.23s/it][A
 41%|████      | 9/22 [00:51<01:22,  6.31s/it][A
 45%|████▌     | 10/22 [00:58<01:16,  6.36s/it][A
 50%|█████     | 11/22 [01:04<01:10,  6.38s/it][A
 55%|█████▍    | 12/22 [01:11<01:03,  6.39s/it][A
 59%|█████▉    | 13/22 [01:17<00:57,  6.40s/it][A
 64%|██████▎   | 14/22 [01:23<00:51,  6.43s/it][A
 68%|██████▊   | 15/22 [01:30<00:44,  6.40s/it][A
 73%|███████▎  | 16/22 [01:36<00:38,  6.46s/it][A
 77%|███████▋  | 17/22 [01:43<00:31,  6.39s/it][A
 82%|████████▏ | 18/22 [01:49<00:25,  6.45s/it][A
 86%|████████▋ | 19/22 [01:56<00:19,  6.44s/it][A
 91%|█████████ | 20/22 [02:02<00:12,  6.44s/it][A
 95%|█████████▌| 21/22 [02:09<00:06,  6.46s/it][A
100%|██████████| 22/22 [02:15<00:00,  6.44s/it][A                                                      
                                               [A{'eval_loss': 0.938866913318634, 'eval_runtime': 141.8889, 'eval_samples_per_second': 1.219, 'eval_steps_per_second': 0.155, 'epoch': 0.39}
 19%|█▉        | 192/1024 [1:08:45<4:37:18, 20.00s/it]
100%|██████████| 22/22 [02:15<00:00,  6.44s/it][A
                                               [A:::MLLOG {"namespace": "", "time_ms": 1754888839244, "event_type": "INTERVAL_END", "key": "block_stop", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 174, "samples_count": 1536}}
:::MLLOG {"namespace": "", "time_ms": 1754888839245, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.938866913318634, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 179, "samples_count": 1536}}
:::MLLOG {"namespace": "", "time_ms": 1754888839245, "event_type": "INTERVAL_START", "key": "block_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 184, "samples_count": 192}}
 19%|█▉        | 193/1024 [1:09:05<14:26:31, 62.57s/it]                                                       {'loss': 1.2535, 'grad_norm': 0.8125505560280966, 'learning_rate': 0.0003662939224605091, 'epoch': 0.4}
 19%|█▉        | 193/1024 [1:09:05<14:26:31, 62.57s/it] 19%|█▉        | 194/1024 [1:09:25<11:28:40, 49.78s/it] 19%|█▉        | 195/1024 [1:09:45<9:24:15, 40.84s/it]  19%|█▉        | 196/1024 [1:10:05<7:57:11, 34.58s/it] 19%|█▉        | 197/1024 [1:10:25<6:56:33, 30.22s/it] 19%|█▉        | 198/1024 [1:10:45<6:14:01, 27.17s/it] 19%|█▉        | 199/1024 [1:11:05<5:44:12, 25.03s/it] 20%|█▉        | 200/1024 [1:11:25<5:23:01, 23.52s/it] 20%|█▉        | 201/1024 [1:11:45<5:08:26, 22.49s/it] 20%|█▉        | 202/1024 [1:12:05<4:57:58, 21.75s/it] 20%|█▉        | 203/1024 [1:12:25<4:50:36, 21.24s/it] 20%|█▉        | 204/1024 [1:12:45<4:45:18, 20.88s/it] 20%|██        | 205/1024 [1:13:05<4:41:26, 20.62s/it] 20%|██        | 206/1024 [1:13:25<4:38:45, 20.45s/it] 20%|██        | 207/1024 [1:13:45<4:36:42, 20.32s/it] 20%|██        | 208/1024 [1:14:05<4:35:19, 20.24s/it] 20%|██        | 209/1024 [1:14:25<4:34:13, 20.19s/it] 21%|██        | 210/1024 [1:14:46<4:33:21, 20.15s/it] 21%|██        | 211/1024 [1:15:06<4:32:40, 20.12s/it] 21%|██        | 212/1024 [1:15:26<4:32:09, 20.11s/it] 21%|██        | 213/1024 [1:15:46<4:31:22, 20.08s/it] 21%|██        | 214/1024 [1:16:06<4:30:31, 20.04s/it] 21%|██        | 215/1024 [1:16:26<4:29:52, 20.02s/it] 21%|██        | 216/1024 [1:16:46<4:29:21, 20.00s/it]                                                      {'loss': 1.2964, 'grad_norm': 0.127224582086345, 'learning_rate': 0.00035804604428746204, 'epoch': 0.44}
 21%|██        | 216/1024 [1:16:46<4:29:21, 20.00s/it]:::MLLOG {"namespace": "", "time_ms": 1754889319752, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2964, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 1728}}
 21%|██        | 217/1024 [1:17:06<4:28:54, 19.99s/it]                                                      {'loss': 1.3288, 'grad_norm': 0.1053418422468677, 'learning_rate': 0.0003576692855253213, 'epoch': 0.44}
 21%|██        | 217/1024 [1:17:06<4:28:54, 19.99s/it] 21%|██▏       | 218/1024 [1:17:26<4:28:33, 19.99s/it] 21%|██▏       | 219/1024 [1:17:46<4:28:18, 20.00s/it] 21%|██▏       | 220/1024 [1:18:05<4:27:43, 19.98s/it] 22%|██▏       | 221/1024 [1:18:25<4:27:31, 19.99s/it] 22%|██▏       | 222/1024 [1:18:46<4:27:15, 19.99s/it] 22%|██▏       | 223/1024 [1:19:05<4:26:50, 19.99s/it] 22%|██▏       | 224/1024 [1:19:25<4:26:34, 19.99s/it] 22%|██▏       | 225/1024 [1:19:46<4:26:27, 20.01s/it] 22%|██▏       | 226/1024 [1:20:06<4:26:16, 20.02s/it] 22%|██▏       | 227/1024 [1:20:26<4:26:03, 20.03s/it] 22%|██▏       | 228/1024 [1:20:46<4:25:47, 20.03s/it] 22%|██▏       | 229/1024 [1:21:06<4:25:22, 20.03s/it] 22%|██▏       | 230/1024 [1:21:26<4:25:14, 20.04s/it] 23%|██▎       | 231/1024 [1:21:46<4:25:03, 20.05s/it] 23%|██▎       | 232/1024 [1:22:06<4:24:50, 20.06s/it] 23%|██▎       | 233/1024 [1:22:26<4:24:22, 20.05s/it] 23%|██▎       | 234/1024 [1:22:46<4:24:04, 20.06s/it] 23%|██▎       | 235/1024 [1:23:06<4:23:47, 20.06s/it] 23%|██▎       | 236/1024 [1:23:26<4:23:16, 20.05s/it] 23%|██▎       | 237/1024 [1:23:46<4:22:25, 20.01s/it] 23%|██▎       | 238/1024 [1:24:06<4:21:56, 20.00s/it] 23%|██▎       | 239/1024 [1:24:26<4:21:35, 19.99s/it] 23%|██▎       | 240/1024 [1:24:46<4:21:08, 19.99s/it]                                                      {'loss': 1.2878, 'grad_norm': 0.1725724474417425, 'learning_rate': 0.00034860159042702436, 'epoch': 0.49}
 23%|██▎       | 240/1024 [1:24:46<4:21:08, 19.99s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:06<01:04,  3.24s/it][A
 14%|█▎        | 3/22 [00:12<01:26,  4.56s/it][A
 18%|█▊        | 4/22 [00:19<01:34,  5.24s/it][A
 23%|██▎       | 5/22 [00:25<01:36,  5.69s/it][A
 27%|██▋       | 6/22 [00:32<01:35,  5.95s/it][A
 32%|███▏      | 7/22 [00:38<01:31,  6.08s/it][A
 36%|███▋      | 8/22 [00:45<01:27,  6.24s/it][A
 41%|████      | 9/22 [00:51<01:22,  6.31s/it][A
 45%|████▌     | 10/22 [00:58<01:15,  6.32s/it][A
 50%|█████     | 11/22 [01:04<01:10,  6.38s/it][A
 55%|█████▍    | 12/22 [01:10<01:03,  6.39s/it][A
 59%|█████▉    | 13/22 [01:17<00:57,  6.40s/it][A
 64%|██████▎   | 14/22 [01:23<00:51,  6.43s/it][A
 68%|██████▊   | 15/22 [01:30<00:44,  6.41s/it][A
 73%|███████▎  | 16/22 [01:36<00:38,  6.44s/it][A
 77%|███████▋  | 17/22 [01:43<00:32,  6.46s/it][A
 82%|████████▏ | 18/22 [01:49<00:25,  6.43s/it][A
 86%|████████▋ | 19/22 [01:56<00:19,  6.42s/it][A
 91%|█████████ | 20/22 [02:02<00:12,  6.46s/it][A
 95%|█████████▌| 21/22 [02:08<00:06,  6.44s/it][A
100%|██████████| 22/22 [02:15<00:00,  6.44s/it][A                                                      
                                               [A{'eval_loss': 0.9365055561065674, 'eval_runtime': 141.8511, 'eval_samples_per_second': 1.22, 'eval_steps_per_second': 0.155, 'epoch': 0.49}
 23%|██▎       | 240/1024 [1:27:08<4:21:08, 19.99s/it]
100%|██████████| 22/22 [02:15<00:00,  6.44s/it][A
                                               [A:::MLLOG {"namespace": "", "time_ms": 1754889941986, "event_type": "INTERVAL_END", "key": "block_stop", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 174, "samples_count": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1754889941987, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9365055561065674, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 179, "samples_count": 1920}}
:::MLLOG {"namespace": "", "time_ms": 1754889941988, "event_type": "INTERVAL_START", "key": "block_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 184, "samples_count": 240}}
 24%|██▎       | 241/1024 [1:27:28<13:36:23, 62.56s/it]                                                       {'loss': 1.2935, 'grad_norm': 0.12293374762858167, 'learning_rate': 0.00034819022507099186, 'epoch': 0.49}
 24%|██▎       | 241/1024 [1:27:28<13:36:23, 62.56s/it] 24%|██▎       | 242/1024 [1:27:48<10:48:55, 49.79s/it] 24%|██▎       | 243/1024 [1:28:08<8:51:47, 40.85s/it]  24%|██▍       | 244/1024 [1:28:28<7:29:43, 34.59s/it] 24%|██▍       | 245/1024 [1:28:48<6:32:12, 30.21s/it] 24%|██▍       | 246/1024 [1:29:08<5:52:00, 27.15s/it] 24%|██▍       | 247/1024 [1:29:28<5:23:50, 25.01s/it] 24%|██▍       | 248/1024 [1:29:48<5:04:01, 23.51s/it] 24%|██▍       | 249/1024 [1:30:08<4:50:19, 22.48s/it] 24%|██▍       | 250/1024 [1:30:28<4:40:33, 21.75s/it] 25%|██▍       | 251/1024 [1:30:48<4:33:47, 21.25s/it] 25%|██▍       | 252/1024 [1:31:08<4:28:48, 20.89s/it] 25%|██▍       | 253/1024 [1:31:28<4:25:12, 20.64s/it] 25%|██▍       | 254/1024 [1:31:48<4:22:24, 20.45s/it] 25%|██▍       | 255/1024 [1:32:08<4:20:15, 20.31s/it] 25%|██▌       | 256/1024 [1:32:28<4:18:45, 20.22s/it] 25%|██▌       | 257/1024 [1:32:48<4:17:38, 20.15s/it] 25%|██▌       | 258/1024 [1:33:08<4:16:42, 20.11s/it] 25%|██▌       | 259/1024 [1:33:28<4:15:57, 20.07s/it] 25%|██▌       | 260/1024 [1:33:48<4:15:10, 20.04s/it] 25%|██▌       | 261/1024 [1:34:08<4:14:49, 20.04s/it] 26%|██▌       | 262/1024 [1:34:28<4:14:32, 20.04s/it] 26%|██▌       | 263/1024 [1:34:48<4:14:13, 20.04s/it] 26%|██▌       | 264/1024 [1:35:08<4:13:44, 20.03s/it]                                                      {'loss': 1.3269, 'grad_norm': 0.08940327555114107, 'learning_rate': 0.00033835185167283157, 'epoch': 0.54}
 26%|██▌       | 264/1024 [1:35:08<4:13:44, 20.03s/it]:::MLLOG {"namespace": "", "time_ms": 1754890422423, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3269, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 2112}}
 26%|██▌       | 265/1024 [1:35:28<4:13:05, 20.01s/it]                                                      {'loss': 1.3708, 'grad_norm': 0.4463862588214245, 'learning_rate': 0.0003379081089474134, 'epoch': 0.54}
 26%|██▌       | 265/1024 [1:35:28<4:13:05, 20.01s/it] 26%|██▌       | 266/1024 [1:35:48<4:12:33, 19.99s/it] 26%|██▌       | 267/1024 [1:36:08<4:12:05, 19.98s/it] 26%|██▌       | 268/1024 [1:36:28<4:11:57, 20.00s/it] 26%|██▋       | 269/1024 [1:36:48<4:11:51, 20.02s/it] 26%|██▋       | 270/1024 [1:37:08<4:11:36, 20.02s/it] 26%|██▋       | 271/1024 [1:37:28<4:11:20, 20.03s/it] 27%|██▋       | 272/1024 [1:37:48<4:11:01, 20.03s/it] 27%|██▋       | 273/1024 [1:38:08<4:10:50, 20.04s/it] 27%|██▋       | 274/1024 [1:38:28<4:10:35, 20.05s/it] 27%|██▋       | 275/1024 [1:38:48<4:10:14, 20.05s/it] 27%|██▋       | 276/1024 [1:39:09<4:09:54, 20.05s/it] 27%|██▋       | 277/1024 [1:39:29<4:09:37, 20.05s/it] 27%|██▋       | 278/1024 [1:39:49<4:09:15, 20.05s/it] 27%|██▋       | 279/1024 [1:40:09<4:08:58, 20.05s/it] 27%|██▋       | 280/1024 [1:40:29<4:08:25, 20.03s/it] 27%|██▋       | 281/1024 [1:40:49<4:07:52, 20.02s/it] 28%|██▊       | 282/1024 [1:41:09<4:07:34, 20.02s/it] 28%|██▊       | 283/1024 [1:41:29<4:07:19, 20.03s/it] 28%|██▊       | 284/1024 [1:41:49<4:07:00, 20.03s/it] 28%|██▊       | 285/1024 [1:42:09<4:06:39, 20.03s/it] 28%|██▊       | 286/1024 [1:42:29<4:06:19, 20.03s/it] 28%|██▊       | 287/1024 [1:42:49<4:06:06, 20.04s/it] 28%|██▊       | 288/1024 [1:43:09<4:05:51, 20.04s/it]                                                      {'loss': 1.3132, 'grad_norm': 0.10069582670715241, 'learning_rate': 0.00032735237224725683, 'epoch': 0.59}
 28%|██▊       | 288/1024 [1:43:09<4:05:51, 20.04s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:06<01:04,  3.22s/it][A
 14%|█▎        | 3/22 [00:12<01:26,  4.58s/it][A
 18%|█▊        | 4/22 [00:19<01:35,  5.29s/it][A
 23%|██▎       | 5/22 [00:25<01:36,  5.69s/it][A
 27%|██▋       | 6/22 [00:32<01:35,  5.96s/it][A
 32%|███▏      | 7/22 [00:38<01:31,  6.10s/it][A
 36%|███▋      | 8/22 [00:45<01:26,  6.20s/it][A
 41%|████      | 9/22 [00:51<01:21,  6.29s/it][A
 45%|████▌     | 10/22 [00:58<01:16,  6.33s/it][A
 50%|█████     | 11/22 [01:04<01:10,  6.40s/it][A
 55%|█████▍    | 12/22 [01:11<01:03,  6.40s/it][A
 59%|█████▉    | 13/22 [01:17<00:58,  6.44s/it][A
 64%|██████▎   | 14/22 [01:23<00:51,  6.40s/it][A
 68%|██████▊   | 15/22 [01:30<00:44,  6.41s/it][A
 73%|███████▎  | 16/22 [01:36<00:38,  6.44s/it][A
 77%|███████▋  | 17/22 [01:43<00:32,  6.47s/it][A
 82%|████████▏ | 18/22 [01:49<00:25,  6.46s/it][A
 86%|████████▋ | 19/22 [01:56<00:19,  6.45s/it][A
 91%|█████████ | 20/22 [02:02<00:12,  6.46s/it][A
 95%|█████████▌| 21/22 [02:09<00:06,  6.44s/it][A
100%|██████████| 22/22 [02:15<00:00,  6.44s/it][A                                                      
                                               [A{'eval_loss': 0.9294281601905823, 'eval_runtime': 142.0006, 'eval_samples_per_second': 1.218, 'eval_steps_per_second': 0.155, 'epoch': 0.59}
 28%|██▊       | 288/1024 [1:45:31<4:05:51, 20.04s/it]
100%|██████████| 22/22 [02:15<00:00,  6.44s/it][A
                                               [A:::MLLOG {"namespace": "", "time_ms": 1754891045106, "event_type": "INTERVAL_END", "key": "block_stop", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 174, "samples_count": 2304}}
:::MLLOG {"namespace": "", "time_ms": 1754891045106, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9294281601905823, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 179, "samples_count": 2304}}
:::MLLOG {"namespace": "", "time_ms": 1754891045107, "event_type": "INTERVAL_START", "key": "block_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 184, "samples_count": 288}}
 28%|██▊       | 289/1024 [1:45:51<12:47:15, 62.63s/it]                                                       {'loss': 1.2314, 'grad_norm': 0.1681653356311719, 'learning_rate': 0.0003268786568327291, 'epoch': 0.59}
 28%|██▊       | 289/1024 [1:45:51<12:47:15, 62.63s/it] 28%|██▊       | 290/1024 [1:46:11<10:09:38, 49.83s/it] 28%|██▊       | 291/1024 [1:46:31<8:19:23, 40.88s/it]  29%|██▊       | 292/1024 [1:46:51<7:02:21, 34.62s/it] 29%|██▊       | 293/1024 [1:47:11<6:08:21, 30.23s/it] 29%|██▊       | 294/1024 [1:47:31<5:30:29, 27.16s/it] 29%|██▉       | 295/1024 [1:47:51<5:03:53, 25.01s/it] 29%|██▉       | 296/1024 [1:48:11<4:45:15, 23.51s/it] 29%|██▉       | 297/1024 [1:48:31<4:32:07, 22.46s/it] 29%|██▉       | 298/1024 [1:48:51<4:22:39, 21.71s/it] 29%|██▉       | 299/1024 [1:49:11<4:16:07, 21.20s/it] 29%|██▉       | 300/1024 [1:49:31<4:11:33, 20.85s/it] 29%|██▉       | 301/1024 [1:49:51<4:08:13, 20.60s/it] 29%|██▉       | 302/1024 [1:50:11<4:05:58, 20.44s/it] 30%|██▉       | 303/1024 [1:50:31<4:03:53, 20.30s/it] 30%|██▉       | 304/1024 [1:50:51<4:02:29, 20.21s/it] 30%|██▉       | 305/1024 [1:51:11<4:01:20, 20.14s/it] 30%|██▉       | 306/1024 [1:51:31<4:00:31, 20.10s/it] 30%|██▉       | 307/1024 [1:51:51<4:00:14, 20.10s/it] 30%|███       | 308/1024 [1:52:11<3:59:53, 20.10s/it] 30%|███       | 309/1024 [1:52:31<3:59:15, 20.08s/it] 30%|███       | 310/1024 [1:52:51<3:58:52, 20.07s/it] 30%|███       | 311/1024 [1:53:11<3:58:21, 20.06s/it] 30%|███       | 312/1024 [1:53:31<3:57:49, 20.04s/it]                                                      {'loss': 1.3024, 'grad_norm': 0.10184046883895087, 'learning_rate': 0.00031566275928233116, 'epoch': 0.64}
 30%|███       | 312/1024 [1:53:31<3:57:49, 20.04s/it]:::MLLOG {"namespace": "", "time_ms": 1754891525430, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.3024, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 2496}}
 31%|███       | 313/1024 [1:53:51<3:57:29, 20.04s/it]                                                      {'loss': 1.3, 'grad_norm': 0.3392254330907177, 'learning_rate': 0.0003151616382835691, 'epoch': 0.64}
 31%|███       | 313/1024 [1:53:51<3:57:29, 20.04s/it] 31%|███       | 314/1024 [1:54:11<3:57:04, 20.03s/it] 31%|███       | 315/1024 [1:54:31<3:56:36, 20.02s/it] 31%|███       | 316/1024 [1:54:51<3:56:10, 20.01s/it] 31%|███       | 317/1024 [1:55:11<3:55:56, 20.02s/it] 31%|███       | 318/1024 [1:55:31<3:55:30, 20.01s/it] 31%|███       | 319/1024 [1:55:51<3:55:05, 20.01s/it] 31%|███▏      | 320/1024 [1:56:11<3:54:38, 20.00s/it] 31%|███▏      | 321/1024 [1:56:31<3:54:22, 20.00s/it] 31%|███▏      | 322/1024 [1:56:51<3:53:59, 20.00s/it] 32%|███▏      | 323/1024 [1:57:11<3:53:38, 20.00s/it] 32%|███▏      | 324/1024 [1:57:31<3:53:16, 19.99s/it] 32%|███▏      | 325/1024 [1:57:51<3:53:01, 20.00s/it] 32%|███▏      | 326/1024 [1:58:11<3:52:38, 20.00s/it] 32%|███▏      | 327/1024 [1:58:31<3:52:17, 20.00s/it] 32%|███▏      | 328/1024 [1:58:51<3:52:01, 20.00s/it] 32%|███▏      | 329/1024 [1:59:11<3:51:35, 19.99s/it] 32%|███▏      | 330/1024 [1:59:31<3:51:17, 20.00s/it] 32%|███▏      | 331/1024 [1:59:51<3:51:00, 20.00s/it] 32%|███▏      | 332/1024 [2:00:11<3:50:37, 20.00s/it] 33%|███▎      | 333/1024 [2:00:31<3:50:15, 19.99s/it] 33%|███▎      | 334/1024 [2:00:51<3:49:52, 19.99s/it] 33%|███▎      | 335/1024 [2:01:11<3:49:42, 20.00s/it] 33%|███▎      | 336/1024 [2:01:31<3:49:29, 20.01s/it]                                                      {'loss': 1.303, 'grad_norm': 0.6672899419959067, 'learning_rate': 0.00030334635980353, 'epoch': 0.69}
 33%|███▎      | 336/1024 [2:01:31<3:49:29, 20.01s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:06<01:04,  3.21s/it][A
 14%|█▎        | 3/22 [00:12<01:26,  4.57s/it][A
 18%|█▊        | 4/22 [00:19<01:35,  5.29s/it][A
 23%|██▎       | 5/22 [00:25<01:36,  5.66s/it][A
 27%|██▋       | 6/22 [00:32<01:35,  5.94s/it][A
 32%|███▏      | 7/22 [00:38<01:31,  6.09s/it][A
 36%|███▋      | 8/22 [00:45<01:26,  6.21s/it][A
 41%|████      | 9/22 [00:51<01:21,  6.27s/it][A
 45%|████▌     | 10/22 [00:58<01:16,  6.36s/it][A
 50%|█████     | 11/22 [01:04<01:09,  6.36s/it][A
 55%|█████▍    | 12/22 [01:11<01:04,  6.43s/it][A
 59%|█████▉    | 13/22 [01:17<00:57,  6.41s/it][A
 64%|██████▎   | 14/22 [01:23<00:51,  6.43s/it][A
 68%|██████▊   | 15/22 [01:30<00:44,  6.40s/it][A
 73%|███████▎  | 16/22 [01:36<00:38,  6.43s/it][A
 77%|███████▋  | 17/22 [01:43<00:32,  6.44s/it][A
 82%|████████▏ | 18/22 [01:49<00:25,  6.41s/it][A
 86%|████████▋ | 19/22 [01:56<00:19,  6.43s/it][A
 91%|█████████ | 20/22 [02:02<00:12,  6.43s/it][A
 95%|█████████▌| 21/22 [02:08<00:06,  6.44s/it][A
100%|██████████| 22/22 [02:15<00:00,  6.45s/it][A                                                      
                                               [A{'eval_loss': 0.9258096218109131, 'eval_runtime': 141.778, 'eval_samples_per_second': 1.22, 'eval_steps_per_second': 0.155, 'epoch': 0.69}
 33%|███▎      | 336/1024 [2:03:53<3:49:29, 20.01s/it]
100%|██████████| 22/22 [02:15<00:00,  6.45s/it][A
                                               [A:::MLLOG {"namespace": "", "time_ms": 1754892147288, "event_type": "INTERVAL_END", "key": "block_stop", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 174, "samples_count": 2688}}
:::MLLOG {"namespace": "", "time_ms": 1754892147288, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9258096218109131, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 179, "samples_count": 2688}}
:::MLLOG {"namespace": "", "time_ms": 1754892147289, "event_type": "INTERVAL_START", "key": "block_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 184, "samples_count": 336}}
 33%|███▎      | 337/1024 [2:04:13<11:56:22, 62.57s/it]                                                       {'loss': 1.2983, 'grad_norm': 0.15587240414303324, 'learning_rate': 0.0003028205488386443, 'epoch': 0.69}
 33%|███▎      | 337/1024 [2:04:13<11:56:22, 62.57s/it] 33%|███▎      | 338/1024 [2:04:33<9:29:21, 49.80s/it]  33%|███▎      | 339/1024 [2:04:53<7:46:29, 40.86s/it] 33%|███▎      | 340/1024 [2:05:13<6:34:32, 34.61s/it] 33%|███▎      | 341/1024 [2:05:33<5:44:06, 30.23s/it] 33%|███▎      | 342/1024 [2:05:53<5:08:35, 27.15s/it] 33%|███▎      | 343/1024 [2:06:13<4:43:44, 25.00s/it] 34%|███▎      | 344/1024 [2:06:33<4:26:19, 23.50s/it] 34%|███▎      | 345/1024 [2:06:53<4:14:08, 22.46s/it] 34%|███▍      | 346/1024 [2:07:13<4:05:21, 21.71s/it] 34%|███▍      | 347/1024 [2:07:33<3:59:13, 21.20s/it] 34%|███▍      | 348/1024 [2:07:53<3:54:44, 20.84s/it] 34%|███▍      | 349/1024 [2:08:13<3:51:29, 20.58s/it] 34%|███▍      | 350/1024 [2:08:33<3:49:14, 20.41s/it] 34%|███▍      | 351/1024 [2:08:53<3:47:31, 20.29s/it] 34%|███▍      | 352/1024 [2:09:13<3:46:10, 20.19s/it] 34%|███▍      | 353/1024 [2:09:33<3:45:10, 20.13s/it] 35%|███▍      | 354/1024 [2:09:53<3:44:16, 20.08s/it] 35%|███▍      | 355/1024 [2:10:13<3:43:51, 20.08s/it] 35%|███▍      | 356/1024 [2:10:33<3:43:10, 20.05s/it] 35%|███▍      | 357/1024 [2:10:53<3:42:34, 20.02s/it] 35%|███▍      | 358/1024 [2:11:13<3:42:05, 20.01s/it] 35%|███▌      | 359/1024 [2:11:33<3:41:35, 19.99s/it] 35%|███▌      | 360/1024 [2:11:53<3:41:12, 19.99s/it]                                                      {'loss': 1.2875, 'grad_norm': 0.17419395117808206, 'learning_rate': 0.0002904699174467542, 'epoch': 0.74}
 35%|███▌      | 360/1024 [2:11:53<3:41:12, 19.99s/it]:::MLLOG {"namespace": "", "time_ms": 1754892627175, "event_type": "POINT_IN_TIME", "key": "train_loss", "value": 1.2875, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 166, "samples_count": 2880}}
 35%|███▌      | 361/1024 [2:12:13<3:40:55, 19.99s/it]                                                      {'loss': 1.2991, 'grad_norm': 0.1954486956647688, 'learning_rate': 0.00028992226593092135, 'epoch': 0.74}
 35%|███▌      | 361/1024 [2:12:13<3:40:55, 19.99s/it] 35%|███▌      | 362/1024 [2:12:33<3:40:30, 19.99s/it] 35%|███▌      | 363/1024 [2:12:53<3:40:01, 19.97s/it] 36%|███▌      | 364/1024 [2:13:13<3:39:44, 19.98s/it] 36%|███▌      | 365/1024 [2:13:33<3:39:14, 19.96s/it] 36%|███▌      | 366/1024 [2:13:53<3:38:55, 19.96s/it] 36%|███▌      | 367/1024 [2:14:13<3:38:37, 19.97s/it] 36%|███▌      | 368/1024 [2:14:33<3:38:18, 19.97s/it] 36%|███▌      | 369/1024 [2:14:53<3:37:56, 19.96s/it] 36%|███▌      | 370/1024 [2:15:13<3:37:35, 19.96s/it] 36%|███▌      | 371/1024 [2:15:33<3:37:21, 19.97s/it] 36%|███▋      | 372/1024 [2:15:53<3:36:57, 19.97s/it] 36%|███▋      | 373/1024 [2:16:13<3:36:43, 19.97s/it] 37%|███▋      | 374/1024 [2:16:33<3:36:25, 19.98s/it] 37%|███▋      | 375/1024 [2:16:53<3:36:11, 19.99s/it] 37%|███▋      | 376/1024 [2:17:13<3:35:56, 19.99s/it] 37%|███▋      | 377/1024 [2:17:33<3:35:39, 20.00s/it] 37%|███▋      | 378/1024 [2:17:53<3:35:18, 20.00s/it] 37%|███▋      | 379/1024 [2:18:13<3:34:59, 20.00s/it] 37%|███▋      | 380/1024 [2:18:33<3:34:42, 20.00s/it] 37%|███▋      | 381/1024 [2:18:53<3:34:20, 20.00s/it] 37%|███▋      | 382/1024 [2:19:13<3:33:56, 19.99s/it] 37%|███▋      | 383/1024 [2:19:33<3:33:26, 19.98s/it] 38%|███▊      | 384/1024 [2:19:53<3:33:04, 19.98s/it]                                                      {'loss': 1.3076, 'grad_norm': 0.13294986630816874, 'learning_rate': 0.00027710321076878383, 'epoch': 0.79}
 38%|███▊      | 384/1024 [2:19:53<3:33:04, 19.98s/it]
  0%|          | 0/22 [00:00<?, ?it/s][A
  9%|▉         | 2/22 [00:06<01:03,  3.18s/it][A
 14%|█▎        | 3/22 [00:12<01:26,  4.56s/it][A
 18%|█▊        | 4/22 [00:19<01:34,  5.27s/it][A
 23%|██▎       | 5/22 [00:25<01:36,  5.67s/it][A
 27%|██▋       | 6/22 [00:32<01:35,  5.97s/it][A
 32%|███▏      | 7/22 [00:38<01:31,  6.11s/it][A
 36%|███▋      | 8/22 [00:45<01:26,  6.21s/it][A
 41%|████      | 9/22 [00:51<01:21,  6.27s/it][A
 45%|████▌     | 10/22 [00:58<01:16,  6.34s/it][A
 50%|█████     | 11/22 [01:04<01:09,  6.32s/it][A
 55%|█████▍    | 12/22 [01:11<01:04,  6.43s/it][A
 59%|█████▉    | 13/22 [01:17<00:57,  6.41s/it][A
 64%|██████▎   | 14/22 [01:23<00:51,  6.42s/it][A
 68%|██████▊   | 15/22 [01:30<00:44,  6.42s/it][A
 73%|███████▎  | 16/22 [01:36<00:38,  6.43s/it][A
 77%|███████▋  | 17/22 [01:43<00:32,  6.43s/it][A
 82%|████████▏ | 18/22 [01:49<00:25,  6.46s/it][A
 86%|████████▋ | 19/22 [01:55<00:19,  6.40s/it][A
 91%|█████████ | 20/22 [02:02<00:12,  6.44s/it][A
 95%|█████████▌| 21/22 [02:08<00:06,  6.45s/it][A
100%|██████████| 22/22 [02:15<00:00,  6.48s/it][A                                                      
                                               [A{'eval_loss': 0.9216886162757874, 'eval_runtime': 141.8586, 'eval_samples_per_second': 1.22, 'eval_steps_per_second': 0.155, 'epoch': 0.79}
 38%|███▊      | 384/1024 [2:22:14<3:33:04, 19.98s/it]
100%|██████████| 22/22 [02:15<00:00,  6.48s/it][A
                                               [A:::MLLOG {"namespace": "", "time_ms": 1754893248542, "event_type": "INTERVAL_END", "key": "block_stop", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 174, "samples_count": 3072}}
:::MLLOG {"namespace": "", "time_ms": 1754893248543, "event_type": "POINT_IN_TIME", "key": "eval_accuracy", "value": 0.9216886162757874, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 179, "samples_count": 3072}}
:::MLLOG {"namespace": "", "time_ms": 1754893248544, "event_type": "INTERVAL_START", "key": "block_start", "value": "", "metadata": {"file": "mlperf_logging_utils.py", "lineno": 184, "samples_count": 384}}
:::MLLOG {"namespace": "", "time_ms": 1754893248544, "event_type": "INTERVAL_END", "key": "run_stop", "value": 0.9216886162757874, "metadata": {"file": "mlperf_logging_utils.py", "lineno": 195, "samples_count": 3072, "status": "success"}}
 38%|███▊      | 385/1024 [2:22:34<11:06:10, 62.55s/it]                                                       {'loss': 1.2658, 'grad_norm': 0.08756970204890407, 'learning_rate': 0.000276536686473018, 'epoch': 0.79}
 38%|███▊      | 385/1024 [2:22:34<11:06:10, 62.55s/it]                                                       {'train_runtime': 8555.8692, 'train_samples_per_second': 0.957, 'train_steps_per_second': 0.12, 'train_loss': 1.368328939165388, 'epoch': 0.79}
 38%|███▊      | 385/1024 [2:22:34<11:06:10, 62.55s/it] 38%|███▊      | 385/1024 [2:22:34<3:56:38, 22.22s/it] 
[1;34mwandb[0m: 
[1;34mwandb[0m: 🚀 View run [33m2025-08-10_20-57-46---llama2-70b-fused-qkv-mlperf[0m at: [34mhttps://wandb.ai/vchua/mlperf-lora/runs/2025-08-10_20-57-46---llama2-70b-fused-qkv-mlperf[0m
[1;34mwandb[0m: Find logs at: [1;35mwandb/run-20250810_205832-2025-08-10_20-57-46---llama2-70b-fused-qkv-mlperf/logs[0m
